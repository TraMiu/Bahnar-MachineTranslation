{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "t-z2YfApAcCI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XsvDNvEzHQ4",
        "outputId": "f1380040-06d2-4331-fd57-e613a470a1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/drive/MyDrive/bdq-mt/bdq-vie-mt\n",
        "%cd /content/drive/MyDrive/bdq-mt/vie-bdq-mt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrtjJ7fvzjeM",
        "outputId": "c5fbba30-6603-4718-ba50-ce9d368f4418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/bdq-mt/vie-bdq-mt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "BbXe-TiWzt0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Filtering\n",
        "*   Deleting empty rows;\n",
        "*   Deleting duplicates;\n",
        "*   Deleting source-copied rows;\n",
        "*   Deleting too long Source/Target (ratio 200% and > 200 words);\n",
        "*   Removing HTML;\n",
        "*   Segments will remain in the true-case unless lower is True;\n",
        "*   Shuffling rows"
      ],
      "metadata": {
        "id": "cstEvPilzrLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/filtering/filter.py /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie  /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq vie bdq"
      ],
      "metadata": {
        "id": "vLz5s17Iz54L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31e208c-c580-4b94-da09-41b7698ccb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape (rows, columns): (35750, 2)\n",
            "--- Rows with Empty Cells Deleted\t--> Rows: 35750\n",
            "--- Duplicates Deleted\t\t\t--> Rows: 35693\n",
            "--- Source-Copied Rows Deleted\t\t--> Rows: 35591\n",
            "--- Too Long Source/Target Deleted\t--> Rows: 34975\n",
            "--- HTML Removed\t\t\t--> Rows: 34975\n",
            "--- Rows will remain in true-cased\t--> Rows: 34975\n",
            "--- Rows with Empty Cells Deleted\t--> Rows: 34975\n",
            "--- Rows Shuffled\t\t\t--> Rows: 34975\n",
            "--- Source Saved: /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie\n",
            "--- Target Saved: /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 3 /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie && echo \"-----\" && head -n 3 /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQd3XP8i0Y9I",
        "outputId": "5c15a77a-a9d4-4e28-8f8e-a49c45fd2e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chúa sẽ ban phước cho anh chị em ở khắp mọi nơi, trong thành thị cũng như ngoài đồng ruộng\n",
            "Ngài dùng quyền năng thiết lập núi non,\n",
            "đứng\n",
            "-----\n",
            "Kră Yang gô ăn kơ iĕm pŭn hiôk tơ jơ̆p-jang anih, tơ lăm pơlei dah tơ mir chŭn\n",
            "Ih yua tơdrong mơsêh pơjing lu kông gei kơjăp,\n",
            "atau\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "E36VEXkYHrNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/train_dev_split/tran_dev_test_split.py 2000 2000 /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZjTcuf2IHnc",
        "outputId": "b52169cb-59d1-4ef9-ef33-ef48ff2acf9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape: (34975, 2)\n",
            "--- Empty Cells Deleted --> Rows: 34975\n",
            "--- Wrote Files\n",
            "Done!\n",
            "Output files\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq.train\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie.train\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq.eval\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie.eval\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq.test\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie.test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n"
      ],
      "metadata": {
        "id": "VY09Oss50IEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a Subwording Model\n"
      ],
      "metadata": {
        "id": "pzXdIA3KAhlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhX9ArmcE7e8",
        "outputId": "106213c7-1f43-42a7-8029-9c7c359073df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "J71TLea4E_kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_source_file_tok = \"/content/drive/MyDrive/bdq-mt/vie-bdq-mt/data/all.vie-bdq.vie-filtered.vie.train\"\n",
        "train_target_file_tok = \"/content/drive/MyDrive/bdq-mt/vie-bdq-mt/data/all.vie-bdq.bdq-filtered.bdq.train\""
      ],
      "metadata": {
        "id": "G18aGoGPFCzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_train_value = '--input='+train_source_file_tok+' --model_prefix=subwording/vie-source --vocab_size=32000 --hard_vocab_limit=false --model_type=bpe --split_digits=true'\n",
        "spm.SentencePieceTrainer.train(source_train_value)\n",
        "print(\"Done, training a SentencepPiece model for the Source finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHz4-YYVAlLQ",
        "outputId": "027e2e4d-01a7-477b-a3a2-9278eb75bc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done, training a SentencepPiece model for the Source finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/subwording/2-subword.py subwording/vie-source.model data/all.vie-bdq.vie-filtered.vie.train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1YBD1GuJU82",
        "outputId": "ceda3fa5-42f7-4201-dfee-2f2fc29ff22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: subwording/vie-source.model\n",
            "Dataset: data/all.vie-bdq.vie-filtered.vie.train\n",
            "Done subwording the file! Output: data/all.vie-bdq.vie-filtered.vie.train.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/subwording/2-subword.py subwording/vie-source.model data/all.vie-bdq.vie-filtered.vie.eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7InkhscaJeQK",
        "outputId": "2ed5f445-0062-416b-9e45-4b27996fc59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: subwording/vie-source.model\n",
            "Dataset: data/all.vie-bdq.vie-filtered.vie.eval\n",
            "Done subwording the file! Output: data/all.vie-bdq.vie-filtered.vie.eval.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_train_value = '--input='+train_target_file_tok+' --model_prefix=subwording/bdq-target --vocab_size=14000 --hard_vocab_limit=false --model_type=bpe --split_digits=true'\n",
        "spm.SentencePieceTrainer.train(target_train_value)\n",
        "print(\"Done, training a SentencepPiece model for the Target finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu4QanegFdYj",
        "outputId": "a8d8da7b-48a9-4868-8df6-336d64dcb7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done, training a SentencepPiece model for the Target finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/subwording/2-subword.py subwording/bdq-target.model data/all.vie-bdq.bdq-filtered.bdq.train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4vUV7UoGEPC",
        "outputId": "751c1721-fde5-4d6d-8ac3-1f950e739cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: subwording/bdq-target.model\n",
            "Dataset: data/all.vie-bdq.bdq-filtered.bdq.train\n",
            "Done subwording the file! Output: data/all.vie-bdq.bdq-filtered.bdq.train.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/subwording/2-subword.py subwording/bdq-target.model data/all.vie-bdq.bdq-filtered.bdq.eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRBPN_mIJKk9",
        "outputId": "44f394c4-f461-4e51-e1eb-5c8f5cc4d466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: subwording/bdq-target.model\n",
            "Dataset: data/all.vie-bdq.bdq-filtered.bdq.eval\n",
            "Done subwording the file! Output: data/all.vie-bdq.bdq-filtered.bdq.eval.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 3 data/all.vie-bdq.vie-filtered.vie.train.subword && echo \"-----\" && head -n 3 data/all.vie-bdq.bdq-filtered.bdq.train.subword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V80YyjPGHTe-",
        "outputId": "edda85a1-897d-4737-bbdd-2eaf943063df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁Chúa ▁sẽ ▁ban ▁phước ▁cho ▁anh ▁chị ▁em ▁ở ▁khắp ▁mọi ▁nơi , ▁trong ▁thành ▁thị ▁cũng ▁như ▁ngoài ▁đồng ▁ruộng\n",
            "▁Ngài ▁dùng ▁quyền ▁năng ▁thiết ▁lập ▁núi ▁non ,\n",
            "▁đứng\n",
            "-----\n",
            "▁Kră ▁Yang ▁gô ▁ăn ▁kơ ▁iĕm ▁pŭn ▁hiôk ▁tơ ▁jơ̆p - jang ▁anih , ▁tơ ▁lăm ▁pơlei ▁dah ▁tơ ▁mir ▁chŭn\n",
            "▁Ih ▁yua ▁tơdrong ▁mơsêh ▁pơjing ▁lu ▁kông ▁gei ▁kơjăp ,\n",
            "▁atau\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained tokenization for Vietnamese Using VNCoreNLP word segmenter and PhoBert Tokenizer\n"
      ],
      "metadata": {
        "id": "t-z2YfApAcCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py_vncorenlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-8fy6ml0Qxy",
        "outputId": "4389d9bb-d4a1-440d-8b47-4216daad2f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py_vncorenlp\n",
            "  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius (from py_vncorenlp)\n",
            "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: py_vncorenlp\n",
            "  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4307 sha256=e6d4568f3c6f73d401653aecacf80aae40a103cc97bd263bb314cf1a80ee0cc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
            "Successfully built py_vncorenlp\n",
            "Installing collected packages: pyjnius, py_vncorenlp\n",
            "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import py_vncorenlp\n",
        "\n",
        "# Automatically download VnCoreNLP components from the original repository\n",
        "# and save them in some local machine folder\n",
        "py_vncorenlp.download_model(save_dir='/content/drive/MyDrive/bdq-vie-mt/vncorenlp')"
      ],
      "metadata": {
        "id": "YXfU1Ddn3sjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the word and sentence segmentation component\n",
        "rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/content/drive/MyDrive/bdq-vie-mt/vncorenlp')"
      ],
      "metadata": {
        "id": "oijyFMla4u0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Công tác phòng chống tội phạm về kinh tế, ma túy, môi trường được tăng cường triển khai, thực hiện đạt kết quả\"\n",
        "\n",
        "output = rdrsegmenter.word_segment(text)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnJYE6k27e8u",
        "outputId": "dc04dce5-5832-462d-a7bb-b5aa9f07666d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Công_tác phòng_chống tội_phạm về kinh_tế , ma_tuý , môi_trường được tăng_cường triển_khai , thực_hiện đạt kết_quả']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxAcBad_Az2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "cBDQy6vCJP4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Configuration"
      ],
      "metadata": {
        "id": "yMiM14CNJI9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install OpenNMT-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZqWCc0YJRTu",
        "outputId": "e0375657-9347-4e1c-87be-ae60b54bb7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-3.4.3-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.2,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.0+cu121)\n",
            "Collecting configargparse (from OpenNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ctranslate2<4,>=3.17 (from OpenNMT-py)\n",
            "  Downloading ctranslate2-3.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.15.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n",
            "Collecting waitress (from OpenNMT-py)\n",
            "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.35 (from OpenNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.1)\n",
            "Collecting sacrebleu (from OpenNMT-py)\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from OpenNMT-py)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel (from OpenNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2.1.0)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n",
            "Collecting portalocker (from sacrebleu->OpenNMT-py)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->OpenNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.10.14)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=2.0.1->OpenNMT-py) (2.1.4)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy->OpenNMT-py) (0.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=2.0.1->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n",
            "Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, OpenNMT-py\n",
            "Successfully installed OpenNMT-py-3.4.3 colorama-0.4.6 configargparse-1.7 ctranslate2-3.24.0 fasttext-wheel-0.9.2 portalocker-2.8.2 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.6.1 sacrebleu-2.4.0 waitress-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the YAML configuration file\n",
        "# On a regular machine, you can create it manually or with nano\n",
        "# Note here we are using some smaller values because the dataset is small\n",
        "# For larger datasets, consider increasing: train_steps, valid_steps, warmup_steps, save_checkpoint_steps, keep_checkpoint\n",
        "\n",
        "config = '''# config.yaml\n",
        "\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: data/all.vie-bdq.vie-filtered.vie.train.subword\n",
        "        path_tgt: data/all.vie-bdq.bdq-filtered.bdq.train.subword\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: data/all.vie-bdq.vie-filtered.vie.eval.subword\n",
        "        path_tgt: data/all.vie-bdq.bdq-filtered.bdq.eval.subword\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/vie-source.vocab\n",
        "tgt_vocab: run/bdq-target.vocab\n",
        "\n",
        "# Vocabulary size - should be the same as in sentence piece\n",
        "src_vocab_size: 32000\n",
        "tgt_vocab_size: 14000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 150\n",
        "src_seq_length: 150\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: subwording/vie-source.model\n",
        "tgt_subword_model: subwording/bdq-target.model\n",
        "\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.viebdq\n",
        "\n",
        "# Stop training if it does not imporve after n validations\n",
        "early_stopping: 4\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 1000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "# keep_checkpoint: 3\n",
        "\n",
        "seed: 3435\n",
        "\n",
        "# Default: 100000 - Train the model to max n steps\n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 3000\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: 1000\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: 1000\n",
        "report_every: 100\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 2048\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 2\n",
        "# warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 8\n",
        "hidden_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ],
      "metadata": {
        "id": "fjdeFaISI5KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrwYg19WKGOE",
        "outputId": "2eebd851-4380-4fbc-896f-f0766a35489f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# config.yaml\n",
            "\n",
            "\n",
            "## Where the samples will be written\n",
            "save_data: run\n",
            "\n",
            "# Training files\n",
            "data:\n",
            "    corpus_1:\n",
            "        path_src: data/all.vie-bdq.vie-filtered.vie.train.subword\n",
            "        path_tgt: data/all.vie-bdq.bdq-filtered.bdq.train.subword\n",
            "        transforms: [filtertoolong]\n",
            "    valid:\n",
            "        path_src: data/all.vie-bdq.vie-filtered.vie.eval.subword\n",
            "        path_tgt: data/all.vie-bdq.bdq-filtered.bdq.eval.subword\n",
            "        transforms: [filtertoolong]\n",
            "\n",
            "# Vocabulary files, generated by onmt_build_vocab\n",
            "src_vocab: run/vie-source.vocab\n",
            "tgt_vocab: run/bdq-target.vocab\n",
            "\n",
            "# Vocabulary size - should be the same as in sentence piece\n",
            "src_vocab_size: 32000\n",
            "tgt_vocab_size: 14000\n",
            "\n",
            "# Filter out source/target longer than n if [filtertoolong] enabled\n",
            "src_seq_length: 150\n",
            "src_seq_length: 150\n",
            "\n",
            "# Tokenization options\n",
            "src_subword_model: subwording/vie-source.model\n",
            "tgt_subword_model: subwording/bdq-target.model\n",
            "\n",
            "# Where to save the log file and the output models/checkpoints\n",
            "log_file: train.log\n",
            "save_model: models/model.viebdq\n",
            "\n",
            "# Stop training if it does not imporve after n validations\n",
            "early_stopping: 4\n",
            "\n",
            "# Default: 5000 - Save a model checkpoint for each n\n",
            "save_checkpoint_steps: 1000\n",
            "\n",
            "# To save space, limit checkpoints to last n\n",
            "# keep_checkpoint: 3\n",
            "\n",
            "seed: 3435\n",
            "\n",
            "# Default: 100000 - Train the model to max n steps\n",
            "# Increase to 200000 or more for large datasets\n",
            "# For fine-tuning, add up the required steps to the original steps\n",
            "train_steps: 3000\n",
            "\n",
            "# Default: 10000 - Run validation after n steps\n",
            "valid_steps: 1000\n",
            "\n",
            "# Default: 4000 - for large datasets, try up to 8000\n",
            "warmup_steps: 1000\n",
            "report_every: 100\n",
            "\n",
            "# Number of GPUs, and IDs of GPUs\n",
            "world_size: 1\n",
            "gpu_ranks: [0]\n",
            "\n",
            "# Batching\n",
            "bucket_size: 262144\n",
            "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
            "batch_type: \"tokens\"\n",
            "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
            "valid_batch_size: 2048\n",
            "max_generator_batches: 2\n",
            "accum_count: [4]\n",
            "accum_steps: [0]\n",
            "\n",
            "# Optimization\n",
            "model_dtype: \"fp16\"\n",
            "optim: \"adam\"\n",
            "learning_rate: 2\n",
            "# warmup_steps: 8000\n",
            "decay_method: \"noam\"\n",
            "adam_beta2: 0.998\n",
            "max_grad_norm: 0\n",
            "label_smoothing: 0.1\n",
            "param_init: 0\n",
            "param_init_glorot: true\n",
            "normalization: \"tokens\"\n",
            "\n",
            "# Model\n",
            "encoder_type: transformer\n",
            "decoder_type: transformer\n",
            "position_encoding: true\n",
            "enc_layers: 6\n",
            "dec_layers: 6\n",
            "heads: 8\n",
            "hidden_size: 512\n",
            "word_vec_size: 512\n",
            "transformer_ff: 2048\n",
            "dropout_steps: [0]\n",
            "dropout: [0.1]\n",
            "attention_dropout: [0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Vocab"
      ],
      "metadata": {
        "id": "-Pbml6meKRu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nproc --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8MnN-vpKJX3",
        "outputId": "bc81a7fc-c9f2-4f68-fa9d-1e0ef48332e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvHTKYRBKU6m",
        "outputId": "bb06df62-51d9-4939-b55f-c3b9d8d980e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-28 20:58:19.216822: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-28 20:58:19.216890: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-28 20:58:19.218148: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-28 20:58:19.227223: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-28 20:58:20.647237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-28 20:58:22.518014: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 20:58:22.518411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 20:58:22.518573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2024-01-28 20:58:22,952 INFO] Counter vocab from -1 samples.\n",
            "[2024-01-28 20:58:22,952 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2024-01-28 20:58:24,583 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=10)\n",
            "\n",
            "[2024-01-28 20:58:24,670 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=18)\n",
            "\n",
            "[2024-01-28 20:58:24,725 INFO] Counters src: 7897\n",
            "[2024-01-28 20:58:24,725 INFO] Counters tgt: 11991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoVIURQOLAnp",
        "outputId": "f354f268-95b9-4eb0-a01e-52b0c4459051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-29494808-7732-ae23-9f6a-1d40772d53c4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "gpu_memory = torch.cuda.mem_get_info(0)\n",
        "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KU7JotMKed4",
        "outputId": "a0c6912f-f467-4b99-ad2a-40ff57dfdbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n",
            "Free GPU memory: 14999.0625 out of: 15102.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ZlcEIP4lLXP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_train -config config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1wk3A4TLacd",
        "outputId": "6b6eb916-675a-4326-83ca-b44a4b88c19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-28 20:58:40.866791: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-28 20:58:40.866844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-28 20:58:40.868080: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-28 20:58:40.875212: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-28 20:58:41.894593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-28 20:58:43.309063: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 20:58:43.309442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 20:58:43.309606: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2024-01-28 20:58:44,087 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2024-01-28 20:58:44,088 INFO] Parsed 2 corpora from -data.\n",
            "[2024-01-28 20:58:44,089 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2024-01-28 20:58:44,159 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '-', '▁', '.', '▁và', '▁các']\n",
            "[2024-01-28 20:58:44,159 INFO] The decoder start token is: <s>\n",
            "[2024-01-28 20:58:44,159 INFO] Building model...\n",
            "[2024-01-28 20:58:45,310 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2024-01-28 20:58:45,311 INFO] Non quantized layer compute is fp16\n",
            "[2024-01-28 20:58:45,571 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(7904, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(12000, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=512, out_features=12000, bias=True)\n",
            ")\n",
            "[2024-01-28 20:58:45,577 INFO] encoder: 22934528\n",
            "[2024-01-28 20:58:45,577 INFO] decoder: 37485280\n",
            "[2024-01-28 20:58:45,577 INFO] * number of parameters: 60419808\n",
            "[2024-01-28 20:58:45,579 INFO] Trainable parameters = {'torch.float32': 60419808, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-01-28 20:58:45,579 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-01-28 20:58:45,579 INFO]  * src vocab size = 7904\n",
            "[2024-01-28 20:58:45,579 INFO]  * tgt vocab size = 12000\n",
            "[2024-01-28 20:58:46,101 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2024-01-28 20:58:46,101 INFO] Starting training on GPU: [0]\n",
            "[2024-01-28 20:58:46,101 INFO] Start training loop and validate every 1000 steps...\n",
            "[2024-01-28 20:58:46,102 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n",
            "[2024-01-28 20:58:47,719 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2024-01-28 20:58:48,784 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2024-01-28 20:58:50,173 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2024-01-28 20:58:52,111 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2024-01-28 20:58:53,813 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2024-01-28 20:58:55,554 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2024-01-28 20:58:56,778 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2024-01-28 20:58:59,278 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2024-01-28 20:59:43,282 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=240)\n",
            "\n",
            "[2024-01-28 20:59:43,282 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2024-01-28 20:59:44,276 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2024-01-28 20:59:45,207 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2024-01-28 20:59:49,118 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2024-01-28 20:59:50,076 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2024-01-28 20:59:51,077 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2024-01-28 20:59:52,070 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2024-01-28 20:59:56,329 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2024-01-28 21:00:31,679 INFO] Step 100/ 3000; acc: 6.7; ppl: 2134.7; xent: 7.7; lr: 0.00028; sents:   62337; bsz: 2932/3120/156; 11109/11819 tok/s;    106 sec;\n",
            "[2024-01-28 21:00:43,173 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=236)\n",
            "\n",
            "[2024-01-28 21:00:43,174 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2024-01-28 21:00:44,147 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2024-01-28 21:00:47,726 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2024-01-28 21:00:49,151 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2024-01-28 21:00:50,732 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2024-01-28 21:00:51,794 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2024-01-28 21:00:56,723 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2024-01-28 21:00:57,610 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2024-01-28 21:00:58,513 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2024-01-28 21:01:46,690 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=236)\n",
            "\n",
            "[2024-01-28 21:01:46,691 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2024-01-28 21:01:47,653 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2024-01-28 21:01:48,605 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2024-01-28 21:01:49,525 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2024-01-28 21:01:53,518 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2024-01-28 21:01:54,417 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2024-01-28 21:01:55,941 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2024-01-28 21:01:57,386 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2024-01-28 21:02:25,139 INFO] Step 200/ 3000; acc: 16.8; ppl: 339.3; xent: 5.8; lr: 0.00056; sents:   59899; bsz: 2881/3075/150; 10158/10840 tok/s;    219 sec;\n",
            "[2024-01-28 21:02:49,367 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=237)\n",
            "\n",
            "[2024-01-28 21:02:49,367 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2024-01-28 21:02:50,352 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2024-01-28 21:02:51,291 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2024-01-28 21:02:52,219 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2024-01-28 21:02:56,226 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2024-01-28 21:02:57,149 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2024-01-28 21:02:58,071 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2024-01-28 21:02:58,999 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2024-01-28 21:03:04,235 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2024-01-28 21:03:47,301 INFO] Step 300/ 3000; acc: 29.1; ppl: 119.6; xent: 4.8; lr: 0.00084; sents:   61039; bsz: 2921/3109/153; 14221/15138 tok/s;    301 sec;\n",
            "[2024-01-28 21:03:51,731 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=237)\n",
            "\n",
            "[2024-01-28 21:03:51,731 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2024-01-28 21:03:52,675 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2024-01-28 21:03:57,081 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2024-01-28 21:03:58,019 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2024-01-28 21:03:58,958 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2024-01-28 21:03:59,880 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2024-01-28 21:04:05,226 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2024-01-28 21:04:06,555 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2024-01-28 21:04:53,780 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=239)\n",
            "\n",
            "[2024-01-28 21:04:53,781 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2024-01-28 21:04:57,751 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2024-01-28 21:04:58,702 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2024-01-28 21:04:59,642 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2024-01-28 21:05:00,582 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2024-01-28 21:05:05,500 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2024-01-28 21:05:07,305 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 58\n",
            "[2024-01-28 21:05:09,116 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 59\n",
            "[2024-01-28 21:05:10,318 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 60\n",
            "[2024-01-28 21:05:45,705 INFO] Step 400/ 3000; acc: 38.3; ppl:  62.7; xent: 4.1; lr: 0.00112; sents:   62570; bsz: 2934/3137/156; 9913/10599 tok/s;    420 sec;\n",
            "[2024-01-28 21:06:01,920 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=234)\n",
            "\n",
            "[2024-01-28 21:06:01,920 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 61\n",
            "[2024-01-28 21:06:02,873 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 62\n",
            "[2024-01-28 21:06:03,818 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 63\n",
            "[2024-01-28 21:06:04,765 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 64\n",
            "[2024-01-28 21:06:09,034 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 65\n",
            "[2024-01-28 21:06:09,969 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 66\n",
            "[2024-01-28 21:06:10,896 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 67\n",
            "[2024-01-28 21:06:12,327 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 68\n",
            "[2024-01-28 21:07:04,609 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=241)\n",
            "\n",
            "[2024-01-28 21:07:04,609 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 69\n",
            "[2024-01-28 21:07:06,379 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 70\n",
            "[2024-01-28 21:07:07,322 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 71\n",
            "[2024-01-28 21:07:08,277 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 72\n",
            "[2024-01-28 21:07:09,228 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 73\n",
            "[2024-01-28 21:07:13,456 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 74\n",
            "[2024-01-28 21:07:14,396 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 75\n",
            "[2024-01-28 21:07:15,318 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 76\n",
            "[2024-01-28 21:07:16,387 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 77\n",
            "[2024-01-28 21:07:38,423 INFO] Step 500/ 3000; acc: 46.8; ppl:  38.6; xent: 3.7; lr: 0.00140; sents:   60229; bsz: 2897/3070/151; 10282/10895 tok/s;    532 sec;\n",
            "[2024-01-28 21:08:06,356 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=232)\n",
            "\n",
            "[2024-01-28 21:08:06,356 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 78\n",
            "[2024-01-28 21:08:08,015 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 79\n",
            "[2024-01-28 21:08:12,485 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 80\n",
            "[2024-01-28 21:08:13,950 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 81\n",
            "[2024-01-28 21:08:15,543 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 82\n",
            "[2024-01-28 21:08:16,534 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 83\n",
            "[2024-01-28 21:08:17,450 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 84\n",
            "[2024-01-28 21:08:22,509 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 85\n",
            "[2024-01-28 21:09:02,934 INFO] Step 600/ 3000; acc: 55.5; ppl:  23.9; xent: 3.2; lr: 0.00168; sents:   61419; bsz: 2910/3099/154; 13773/14669 tok/s;    617 sec;\n",
            "[2024-01-28 21:09:09,942 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=241)\n",
            "\n",
            "[2024-01-28 21:09:09,943 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 86\n",
            "[2024-01-28 21:09:14,435 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 87\n",
            "[2024-01-28 21:09:15,380 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 88\n",
            "[2024-01-28 21:09:16,328 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 89\n",
            "[2024-01-28 21:09:17,270 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 90\n",
            "[2024-01-28 21:09:21,979 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 91\n",
            "[2024-01-28 21:09:23,777 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 92\n",
            "[2024-01-28 21:09:25,549 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 93\n",
            "[2024-01-28 21:09:27,011 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 94\n",
            "[2024-01-28 21:10:18,168 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=234)\n",
            "\n",
            "[2024-01-28 21:10:18,168 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 95\n",
            "[2024-01-28 21:10:19,111 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 96\n",
            "[2024-01-28 21:10:20,052 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 97\n",
            "[2024-01-28 21:10:20,997 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 98\n",
            "[2024-01-28 21:10:25,230 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 99\n",
            "[2024-01-28 21:10:26,173 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 100\n",
            "[2024-01-28 21:10:27,098 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 101\n",
            "[2024-01-28 21:10:28,062 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 102\n",
            "[2024-01-28 21:11:01,336 INFO] Step 700/ 3000; acc: 60.8; ppl:  18.1; xent: 2.9; lr: 0.00196; sents:   61815; bsz: 2936/3142/155; 9917/10616 tok/s;    735 sec;\n",
            "[2024-01-28 21:11:20,573 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=238)\n",
            "\n",
            "[2024-01-28 21:11:20,573 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 103\n",
            "[2024-01-28 21:11:22,158 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 104\n",
            "[2024-01-28 21:11:23,111 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 105\n",
            "[2024-01-28 21:11:24,054 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 106\n",
            "[2024-01-28 21:11:24,992 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 107\n",
            "[2024-01-28 21:11:29,261 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 108\n",
            "[2024-01-28 21:11:30,204 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 109\n",
            "[2024-01-28 21:11:31,142 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 110\n",
            "[2024-01-28 21:11:32,132 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 111\n",
            "[2024-01-28 21:12:25,809 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=235)\n",
            "\n",
            "[2024-01-28 21:12:25,810 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 112\n",
            "[2024-01-28 21:12:26,764 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 113\n",
            "[2024-01-28 21:12:27,709 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 114\n",
            "[2024-01-28 21:12:28,660 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 115\n",
            "[2024-01-28 21:12:33,411 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 116\n",
            "[2024-01-28 21:12:34,408 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 117\n",
            "[2024-01-28 21:12:35,385 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 118\n",
            "[2024-01-28 21:12:36,970 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 119\n",
            "[2024-01-28 21:12:55,648 INFO] Step 800/ 3000; acc: 62.7; ppl:  16.2; xent: 2.8; lr: 0.00224; sents:   61411; bsz: 2906/3099/154; 10169/10844 tok/s;    850 sec;\n",
            "[2024-01-28 21:13:26,139 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=240)\n",
            "\n",
            "[2024-01-28 21:13:26,140 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 120\n",
            "[2024-01-28 21:13:27,767 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 121\n",
            "[2024-01-28 21:13:28,950 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 122\n",
            "[2024-01-28 21:13:33,069 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 123\n",
            "[2024-01-28 21:13:34,009 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 124\n",
            "[2024-01-28 21:13:34,950 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 125\n",
            "[2024-01-28 21:13:35,882 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 126\n",
            "[2024-01-28 21:13:36,815 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 127\n",
            "[2024-01-28 21:14:20,055 INFO] Step 900/ 3000; acc: 66.0; ppl:  13.9; xent: 2.6; lr: 0.00252; sents:   60379; bsz: 2911/3099/151; 13795/14688 tok/s;    934 sec;\n",
            "[2024-01-28 21:14:29,728 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=236)\n",
            "\n",
            "[2024-01-28 21:14:29,729 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 128\n",
            "[2024-01-28 21:14:31,557 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 129\n",
            "[2024-01-28 21:14:33,292 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 130\n",
            "[2024-01-28 21:14:37,368 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 131\n",
            "[2024-01-28 21:14:38,354 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 132\n",
            "[2024-01-28 21:14:39,309 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 133\n",
            "[2024-01-28 21:14:40,255 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 134\n",
            "[2024-01-28 21:14:45,521 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 135\n",
            "[2024-01-28 21:14:46,852 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 136\n",
            "[2024-01-28 21:15:38,443 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=236)\n",
            "\n",
            "[2024-01-28 21:15:38,443 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 137\n",
            "[2024-01-28 21:15:40,191 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 138\n",
            "[2024-01-28 21:15:41,618 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 139\n",
            "[2024-01-28 21:15:42,567 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 140\n",
            "[2024-01-28 21:15:46,923 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 141\n",
            "[2024-01-28 21:15:47,863 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 142\n",
            "[2024-01-28 21:15:49,269 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 143\n",
            "[2024-01-28 21:15:50,861 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 144\n",
            "[2024-01-28 21:16:20,107 INFO] Step 1000/ 3000; acc: 67.7; ppl:  12.8; xent: 2.5; lr: 0.00279; sents:   61842; bsz: 2901/3086/155; 9666/10284 tok/s;   1054 sec;\n",
            "[2024-01-28 21:16:21,156 INFO] valid stats calculation\n",
            "                           took: 1.0478549003601074 s.\n",
            "[2024-01-28 21:16:21,157 INFO] Train perplexity: 55.2189\n",
            "[2024-01-28 21:16:21,157 INFO] Train accuracy: 45.0266\n",
            "[2024-01-28 21:16:21,157 INFO] Sentences processed: 612940\n",
            "[2024-01-28 21:16:21,158 INFO] Average bsz: 2913/3104/153\n",
            "[2024-01-28 21:16:21,158 INFO] Validation perplexity: 36.4567\n",
            "[2024-01-28 21:16:21,158 INFO] Validation accuracy: 53.155\n",
            "[2024-01-28 21:16:21,158 INFO] Model is improving ppl: inf --> 36.4567.\n",
            "[2024-01-28 21:16:21,158 INFO] Model is improving acc: -inf --> 53.155.\n",
            "[2024-01-28 21:16:21,162 INFO] Saving checkpoint models/model.viebdq_step_1000.pt\n",
            "[2024-01-28 21:16:46,572 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=238)\n",
            "\n",
            "[2024-01-28 21:16:46,573 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 145\n",
            "[2024-01-28 21:16:48,052 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 146\n",
            "[2024-01-28 21:16:49,010 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 147\n",
            "[2024-01-28 21:16:49,968 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 148\n",
            "[2024-01-28 21:16:54,798 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 149\n",
            "[2024-01-28 21:16:55,993 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 150\n",
            "[2024-01-28 21:16:56,940 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 151\n",
            "[2024-01-28 21:16:57,902 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 152\n",
            "[2024-01-28 21:17:02,678 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 153\n",
            "[2024-01-28 21:17:48,546 INFO] Step 1100/ 3000; acc: 70.7; ppl:  11.3; xent: 2.4; lr: 0.00266; sents:   61491; bsz: 2925/3110/154; 13229/14066 tok/s;   1142 sec;\n",
            "[2024-01-28 21:17:50,351 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=236)\n",
            "\n",
            "[2024-01-28 21:17:50,351 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 154\n",
            "[2024-01-28 21:17:51,307 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 155\n",
            "[2024-01-28 21:17:55,775 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 156\n",
            "[2024-01-28 21:17:57,229 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 157\n",
            "[2024-01-28 21:17:58,177 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 158\n",
            "[2024-01-28 21:17:59,653 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 159\n",
            "[2024-01-28 21:18:04,810 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 160\n",
            "[2024-01-28 21:18:05,751 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 161\n",
            "[2024-01-28 21:18:55,585 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=239)\n",
            "\n",
            "[2024-01-28 21:18:55,586 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 162\n",
            "[2024-01-28 21:18:56,560 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 163\n",
            "[2024-01-28 21:18:57,517 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 164\n",
            "[2024-01-28 21:18:58,579 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 165\n",
            "[2024-01-28 21:19:05,534 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 166\n",
            "[2024-01-28 21:19:07,125 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 167\n",
            "[2024-01-28 21:19:08,076 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 168\n",
            "[2024-01-28 21:19:09,036 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 169\n",
            "[2024-01-28 21:19:09,968 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 170\n",
            "[2024-01-28 21:19:48,583 INFO] Step 1200/ 3000; acc: 76.4; ppl:   9.0; xent: 2.2; lr: 0.00255; sents:   62148; bsz: 2882/3096/155; 9604/10316 tok/s;   1262 sec;\n",
            "[2024-01-28 21:20:02,603 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=236)\n",
            "\n",
            "[2024-01-28 21:20:02,604 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 171\n",
            "[2024-01-28 21:20:03,552 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 172\n",
            "[2024-01-28 21:20:04,508 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 173\n",
            "[2024-01-28 21:20:08,940 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 174\n",
            "[2024-01-28 21:20:09,961 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 175\n",
            "[2024-01-28 21:20:11,564 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 176\n",
            "[2024-01-28 21:20:13,062 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 177\n",
            "[2024-01-28 21:20:14,020 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 178\n",
            "[2024-01-28 21:21:05,546 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=239)\n",
            "\n",
            "[2024-01-28 21:21:05,546 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 179\n",
            "[2024-01-28 21:21:06,524 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 180\n",
            "[2024-01-28 21:21:07,483 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 181\n",
            "[2024-01-28 21:21:12,044 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 182\n",
            "[2024-01-28 21:21:13,291 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 183\n",
            "[2024-01-28 21:21:14,936 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 184\n",
            "[2024-01-28 21:21:16,069 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 185\n",
            "[2024-01-28 21:21:21,337 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 186\n",
            "[2024-01-28 21:21:22,609 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 187\n",
            "[2024-01-28 21:21:46,091 INFO] Step 1300/ 3000; acc: 80.3; ppl:   7.8; xent: 2.0; lr: 0.00245; sents:   62420; bsz: 2947/3127/156; 10031/10646 tok/s;   1380 sec;\n",
            "[2024-01-28 21:22:11,476 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=233)\n",
            "\n",
            "[2024-01-28 21:22:11,476 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 188\n",
            "[2024-01-28 21:22:15,678 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 189\n",
            "[2024-01-28 21:22:16,629 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 190\n",
            "[2024-01-28 21:22:17,566 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 191\n",
            "[2024-01-28 21:22:18,518 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 192\n",
            "[2024-01-28 21:22:23,060 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 193\n",
            "[2024-01-28 21:22:24,022 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 194\n",
            "[2024-01-28 21:22:25,752 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 195\n",
            "[2024-01-28 21:23:10,690 INFO] Step 1400/ 3000; acc: 84.0; ppl:   6.8; xent: 1.9; lr: 0.00236; sents:   59672; bsz: 2915/3098/149; 13781/14647 tok/s;   1465 sec;\n",
            "[2024-01-28 21:23:15,290 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=240)\n",
            "\n",
            "[2024-01-28 21:23:15,290 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 196\n",
            "[2024-01-28 21:23:16,266 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 197\n",
            "[2024-01-28 21:23:17,210 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 198\n",
            "[2024-01-28 21:23:21,724 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 199\n",
            "[2024-01-28 21:23:22,725 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 200\n",
            "[2024-01-28 21:23:23,668 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 201\n",
            "[2024-01-28 21:23:24,616 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 202\n",
            "[2024-01-28 21:23:25,560 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 203\n",
            "[2024-01-28 21:23:30,478 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 204\n",
            "[2024-01-28 21:24:19,552 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=234)\n",
            "\n",
            "[2024-01-28 21:24:19,553 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 205\n",
            "[2024-01-28 21:24:20,515 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 206\n",
            "[2024-01-28 21:24:25,173 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 207\n",
            "[2024-01-28 21:24:26,567 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 208\n",
            "[2024-01-28 21:24:27,504 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 209\n",
            "[2024-01-28 21:24:28,461 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 210\n",
            "[2024-01-28 21:24:33,132 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 211\n",
            "[2024-01-28 21:24:34,081 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 212\n",
            "[2024-01-28 21:25:07,283 INFO] Step 1500/ 3000; acc: 87.0; ppl:   6.1; xent: 1.8; lr: 0.00228; sents:   61541; bsz: 2943/3133/154; 10097/10749 tok/s;   1581 sec;\n",
            "[2024-01-28 21:25:24,106 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=239)\n",
            "\n",
            "[2024-01-28 21:25:24,106 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 213\n",
            "[2024-01-28 21:25:25,072 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 214\n",
            "[2024-01-28 21:25:26,027 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 215\n",
            "[2024-01-28 21:25:26,973 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 216\n",
            "[2024-01-28 21:25:31,599 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 217\n",
            "[2024-01-28 21:25:32,541 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 218\n",
            "[2024-01-28 21:25:33,501 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 219\n",
            "[2024-01-28 21:25:34,448 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 220\n",
            "[2024-01-28 21:25:35,381 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 221\n",
            "[2024-01-28 21:26:28,123 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=234)\n",
            "\n",
            "[2024-01-28 21:26:28,123 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 222\n",
            "[2024-01-28 21:26:30,112 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 223\n",
            "[2024-01-28 21:26:31,833 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 224\n",
            "[2024-01-28 21:26:33,456 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 225\n",
            "[2024-01-28 21:26:38,833 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 226\n",
            "[2024-01-28 21:26:39,778 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 227\n",
            "[2024-01-28 21:26:40,743 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 228\n",
            "[2024-01-28 21:26:41,691 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 229\n",
            "[2024-01-28 21:27:06,582 INFO] Step 1600/ 3000; acc: 88.7; ppl:   5.8; xent: 1.8; lr: 0.00221; sents:   60976; bsz: 2876/3068/152; 9642/10286 tok/s;   1700 sec;\n",
            "[2024-01-28 21:27:34,917 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=240)\n",
            "\n",
            "[2024-01-28 21:27:34,918 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 230\n",
            "[2024-01-28 21:27:36,300 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 231\n",
            "[2024-01-28 21:27:38,122 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 232\n",
            "[2024-01-28 21:27:39,990 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 233\n",
            "[2024-01-28 21:27:44,610 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 234\n",
            "[2024-01-28 21:27:45,556 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 235\n",
            "[2024-01-28 21:27:46,507 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 236\n",
            "[2024-01-28 21:27:47,445 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 237\n",
            "[2024-01-28 21:28:31,854 INFO] Step 1700/ 3000; acc: 90.6; ppl:   5.4; xent: 1.7; lr: 0.00214; sents:   62059; bsz: 2934/3123/155; 13765/14650 tok/s;   1786 sec;\n",
            "[2024-01-28 21:28:39,687 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=236)\n",
            "\n",
            "[2024-01-28 21:28:39,687 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 238\n",
            "[2024-01-28 21:28:41,470 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 239\n",
            "[2024-01-28 21:28:43,432 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 240\n",
            "[2024-01-28 21:28:45,522 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 241\n",
            "[2024-01-28 21:28:50,444 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 242\n",
            "[2024-01-28 21:28:51,400 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 243\n",
            "[2024-01-28 21:28:52,350 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 244\n",
            "[2024-01-28 21:28:53,298 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 245\n",
            "[2024-01-28 21:28:54,241 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 246\n",
            "[2024-01-28 21:29:48,254 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=236)\n",
            "\n",
            "[2024-01-28 21:29:48,254 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 247\n",
            "[2024-01-28 21:29:49,768 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 248\n",
            "[2024-01-28 21:29:51,409 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 249\n",
            "[2024-01-28 21:29:52,393 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 250\n",
            "[2024-01-28 21:29:56,631 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 251\n",
            "[2024-01-28 21:29:57,579 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 252\n",
            "[2024-01-28 21:29:58,960 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 253\n",
            "[2024-01-28 21:30:00,620 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 254\n",
            "[2024-01-28 21:30:32,616 INFO] Step 1800/ 3000; acc: 92.2; ppl:   5.2; xent: 1.6; lr: 0.00208; sents:   61810; bsz: 2913/3107/155; 9648/10293 tok/s;   1907 sec;\n",
            "[2024-01-28 21:30:52,266 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=239)\n",
            "\n",
            "[2024-01-28 21:30:52,267 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 255\n",
            "[2024-01-28 21:30:53,329 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 256\n",
            "[2024-01-28 21:30:54,307 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 257\n",
            "[2024-01-28 21:30:55,776 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 258\n",
            "[2024-01-28 21:31:00,341 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 259\n",
            "[2024-01-28 21:31:01,332 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 260\n",
            "[2024-01-28 21:31:02,280 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 261\n",
            "[2024-01-28 21:31:03,772 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 262\n",
            "[2024-01-28 21:31:09,098 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 263\n",
            "[2024-01-28 21:31:56,423 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=235)\n",
            "\n",
            "[2024-01-28 21:31:56,423 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 264\n",
            "[2024-01-28 21:31:57,386 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 265\n",
            "[2024-01-28 21:32:01,989 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 266\n",
            "[2024-01-28 21:32:02,953 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 267\n",
            "[2024-01-28 21:32:03,919 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 268\n",
            "[2024-01-28 21:32:04,862 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 269\n",
            "[2024-01-28 21:32:10,021 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 270\n",
            "[2024-01-28 21:32:10,965 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 271\n",
            "[2024-01-28 21:32:27,932 INFO] Step 1900/ 3000; acc: 93.1; ppl:   5.0; xent: 1.6; lr: 0.00203; sents:   60798; bsz: 2905/3096/152; 10075/10739 tok/s;   2022 sec;\n",
            "[2024-01-28 21:32:59,454 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=239)\n",
            "\n",
            "[2024-01-28 21:32:59,454 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 272\n",
            "[2024-01-28 21:33:03,353 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 273\n",
            "[2024-01-28 21:33:04,354 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 274\n",
            "[2024-01-28 21:33:05,310 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 275\n",
            "[2024-01-28 21:33:06,272 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 276\n",
            "[2024-01-28 21:33:12,064 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 277\n",
            "[2024-01-28 21:33:13,189 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 278\n",
            "[2024-01-28 21:33:14,135 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 279\n",
            "[2024-01-28 21:33:15,081 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 280\n",
            "[2024-01-28 21:33:54,903 INFO] Step 2000/ 3000; acc: 94.2; ppl:   4.8; xent: 1.6; lr: 0.00198; sents:   61263; bsz: 2911/3103/153; 13388/14273 tok/s;   2109 sec;\n",
            "[2024-01-28 21:33:54,982 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=3)\n",
            "\n",
            "[2024-01-28 21:33:55,971 INFO] valid stats calculation\n",
            "                           took: 1.065654993057251 s.\n",
            "[2024-01-28 21:33:55,972 INFO] Train perplexity: 18.8988\n",
            "[2024-01-28 21:33:55,972 INFO] Train accuracy: 65.3765\n",
            "[2024-01-28 21:33:55,972 INFO] Sentences processed: 1.22712e+06\n",
            "[2024-01-28 21:33:55,972 INFO] Average bsz: 2914/3105/153\n",
            "[2024-01-28 21:33:55,972 INFO] Validation perplexity: 33.2484\n",
            "[2024-01-28 21:33:55,972 INFO] Validation accuracy: 60.7982\n",
            "[2024-01-28 21:33:55,972 INFO] Model is improving ppl: 36.4567 --> 33.2484.\n",
            "[2024-01-28 21:33:55,972 INFO] Model is improving acc: 53.155 --> 60.7982.\n",
            "[2024-01-28 21:33:55,977 INFO] Saving checkpoint models/model.viebdq_step_2000.pt\n",
            "[2024-01-28 21:34:19,613 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=237)\n",
            "\n",
            "[2024-01-28 21:34:19,615 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 281\n",
            "[2024-01-28 21:34:21,478 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "L9X1d4orL0ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !onmt_translate -model models/model.bdqvie_step_3000.pt -src data/paralle.vie-bdq.bdq-filtered.bdq.subword.test -output data/paralle.vie.translated -gpu 0 -min_length 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRWrGsOVLj5L",
        "outputId": "6e1c00e8-6919-47d2-9f66-6cb8a11219da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-28 17:06:28.304060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-28 17:06:28.304121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-28 17:06:28.305523: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-28 17:06:28.313047: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-28 17:06:29.423848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-28 17:06:31.458443: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 17:06:31.458998: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 17:06:31.459211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2024-01-28 17:06:32,864 INFO] Loading checkpoint from models/model.bdqvie_step_3000.pt\n",
            "[2024-01-28 17:06:40,514 INFO] Loading data into the model\n",
            "[2024-01-28 17:07:15,126 INFO] PRED SCORE: -0.1126, PRED PPL: 1.12 NB SENTENCES: 2000\n",
            "Time w/o python interpreter load/terminate:  42.65310287475586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !tail -n 5 data/paralle.vie-bdq.bdq-filtered.bdq.subword.test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oT-1HTRLtgS",
        "outputId": "e77c997c-d63d-4ad7-cd9b-8e0fbe0168c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁' Nĕ ▁kơ ▁achăng ▁bôl ▁buăl ▁ih ▁dah ▁buăl ▁juăt ▁' bă ▁ih ,\n",
            "▁puôn\n",
            "▁chơpuih ▁( hnam )\n",
            "▁' Boi ▁quy ▁hoach ▁kŭm ▁trương ▁đơ̆ng ▁khu ▁vưk ▁lơ̆m ▁apung ▁teh ▁ngoai ▁thanh ▁uĕi ▁lơ̆m ▁kơbră ▁phương ▁Nhơn ▁Phŭ ▁jê̆ ▁Trương ▁Cao ▁đăng ▁' Binh ▁Đinh ▁weng ▁Trương ▁Đai ▁hŏk ▁Kuang ▁Trung\n",
            "▁Baasa ▁lôch ▁năm ▁oei ▁hơdai ▁hăm ▁lu ▁' bok ▁kơdră ▁sư , ▁păng ▁đe ▁' bŭ ▁sư ▁tơ ▁Pơlei ▁Tirsa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !tail -n 5 data/paralle.vie.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQzvWSBhMq_P",
        "outputId": "63c830d3-dfad-4ebf-aa3a-38b9b2941b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁Đừng ▁từ ▁bỏ ▁bạn ▁con ▁hay ▁bạn ▁của ▁cha ▁con ;\n",
            "▁bốn\n",
            "▁quét ▁( nhà )\n",
            "▁Theo ▁quy ▁hoạch ▁cụm ▁trường ▁của ▁khu ▁vực ▁tại ▁khu ▁đất ▁ngoại ▁thành ▁thuộc ▁phường ▁Nhơn ▁Phú ▁gần ▁Trường ▁Cao ▁đẳng ▁Bình ▁Định ▁và ▁Trường ▁Đại ▁học ▁Quang ▁Trung .\n",
            "▁Ba - ê - sa ▁an ▁giấc ▁với ▁các ▁tổ ▁phụ ▁mình ▁và ▁được ▁chôn ▁tại ▁Tiệt - sa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Desubword the translation file\n",
        "# !python /content/drive/MyDrive/bdq-mt/data-processing/subwording/3-desubword.py subwording/target.model data/paralle.vie.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzCdR_IbM0En",
        "outputId": "9976dee3-ba7a-467f-ff77-c09fc010e285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: data/paralle.vie.translated.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Desubword the target file (reference) of the test dataset\n",
        "# !python3 /content/drive/MyDrive/bdq-mt/data-processing/subwording/3-desubword.py subwording/target.model data/paralle.vie-bdq.vie-filtered.vie.subword.test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg9dipWUNc6k",
        "outputId": "28bee71c-cf41-4f9e-d0a6-3e0a2f30fbf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: data/paralle.vie-bdq.vie-filtered.vie.subword.test.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ctranslate2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKqrCSgn5XPv",
        "outputId": "bac164a4-8134-45fb-a545-5360ed4f1cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ctranslate2 in /usr/local/lib/python3.10/dist-packages (3.24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (1.23.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ct2-opennmt-py-converter --model_path models/model.viebdq_step_3000.pt --output_dir models/viba_ctranslate2 --quantization int8"
      ],
      "metadata": {
        "id": "zLxDeabq5hX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/evaluation/translate.py data/all.vie-bdq.vie-filtered.vie.test subwording/vie-source.model subwording/bdq-target.model models/viba_ctranslate2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3SX_mx96BBK",
        "outputId": "98971bd0-197e-4cc6-a03e-502dba41731c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 data/all.vie-bdq.vie-filtered.vie.test.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdzMg3WW6nSt",
        "outputId": "a27c3b57-8f9a-4380-9337-47c1145715d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Long điêu ơĭ rim tơdrong wă đĕi alưng weng đa dang, phong dơt jơrông jĭ pơm adrĭng lư sơnăm duh đô sa weng truh yan tŏ phang la minh bia pơgloh tơdrong yăl arih piêu rim 'long pơjing dêh sư pơjing hơgĕi adrĭng măt bal loi tơdrong yăl arih, kơjung thoi 'long pơtăm, mua thu 'yŏk, tơjul tĭnh jơnŭm noh\n",
            "Thoi noh, Jôsep 'nĕ kơ 'bôh, 'bă sư, yua kơ sư đei 'bôh 'nhŏng oh sư oei pă thoi 'ngam dơ̆ng\n",
            "Set arih đei tơsĭn-hrĕng mơjĭt-'bar sơnăm, sư lôch\n",
            "Hăm đei bu gơh tơl Kră Yang 'Bok Kei-Dei:\n",
            "Lơm drong 'bô sung rim liên koan truh drong hoat đô̆ng dĭ 'Ban koan ly̆ Yi tich\n",
            "chăng hơ\n",
            "Yua kơ Kră Yang khan kơ inh thoi âu: “Inh khan kơ iĕm tơpă, lu bơngai tơmoi gô pơm tôm tơdrong ư-ang kơ đĭ-đăng lu iĕm gô arih\n",
            "Đawit khan kơ đĭ-đăng lu kon pơlei pơla: Sôlômôn kon drŏ-nglo inh, lu 'nhŏng oh inh, mă-lei lu hơ'lơ̆p bơ̆n ưh kơ đei pơm kiơ, mă-lei sư kư̆m ưh kơ đei pơm ôh tơdrong noh 'Bok Kei-Dei ăn kơ sư\n",
            "Jơnang pơm: Đơ̆ng khĕi tơxĭnh sơnăm 'băl ơbơ̆u không hriêng minh jĭt tơhngam truh khĕi minh jĭt 'băl sơnăm 'băl ơbơ̆u không hriêng 'băl jĭt pơđăm (lơ̆m 'năr tơxĭnh khĕi tơxĭnh sơnăm 'băl ơbơ̆u không hriêng le tơxĭnh\n",
            "bơlŏ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 data/all.vie-bdq.bdq-filtered.bdq.test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8DEULDm6n1F",
        "outputId": "a2065025-4ceb-4df1-bc49-aa38453efc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Long điêu chiu đĕi rim tơdrong plênh đa yang weng khăk nghiêt. Plênh nhiêt đơĭ adrĭng lương ami rim sơnăm duh weng ơĭ minh mua khô ro rêt la rim tơdrong pơgloh sư 'long điêu pơjing hơgĕi. Đô đuuôĭ dơnŏ pơtăm điêu pơting adrĭng măt đak tơsĭ kang grông thoi 'long yăl arih kang đunh, thu 'yŏk kang tơjul\n",
            "Lu 'nhŏng sư 'bôh 'bă sư 'mêm kơ Jôsep hloh kơ lu sư, na lu sư đei jơhngơ̆m klai monh kơ Jôsep, đơ̆ng noh ưh pă gơh pơma pơ'lơ̆ng hăm sư dơ̆ng\n",
            "Thoi noh Set arih đei tơsĭn-hrĕng mơjĭt-'bar sơnăm na sư lôch\n",
            "Hăm đei bơngai bu khan kơ Kră Yang 'Bok Kei-Dei:\n",
            "hoăk 'bô sung rim chinh sach ơ̆i liên koan truh hoat đô̆ng dĭ 'Ban koan ly̆ yi tich\n",
            "yưm\n",
            "Kră Yang khan kơ inh thoi âu: “Lăm minh sơnăm dơ̆ng, jô̆ thoi sơnăm đe jang apah, dôm tơdrong ư-ang dêh char Kêdar gô hiong\n",
            "Đawit khan kơ đĭ-đăng tơpôl akŭm: “Sôlômôn, kon drŏ-nglo inh mă Kră Yang 'Bok Kei-Dei đei rơih iŏk, oei hơ'lơ̆p, sư tam mă biơh băt tơdrong jang âu tih dêh, yua kơ pơm hnam ưh kơ trŏ pơm kơ bơngai ôh, mă-lei hnam 'noh pơm ăn kơ Kră Yang 'Bok Kei-Dei\n",
            "Jơnang pơm: Đơ̆ng khĕi tơxĭnh sơnăm 'băl ơbơ̆u minh jĭt tơhngam truh đĭ khĕi minh jĭt 'băl sơnăm 'băl ơbơ̆u 'băl jĭt (pơđăm hŏk ky, dang dang tơxĭnh jĭt tuân 'boi sơnăm hŏk)\n",
            "grŭn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "IAltMCfWL1zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3z8gmYDN4Xu",
        "outputId": "4a4bbe70-de7f-4b05-cacc-796a07f78b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/bdq-mt/evaluation/eval-metrics.py   data/all.vie-bdq.bdq-filtered.bdq.test data/all.vie-bdq.vie-filtered.vie.test.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyBcxG4SObrk",
        "outputId": "61bb17cf-c064-426f-c251-dcd798d6ea26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU:  39.08\n",
            "CHRF: 55.73\n",
            "TER: 54.49\n"
          ]
        }
      ]
    }
  ]
}