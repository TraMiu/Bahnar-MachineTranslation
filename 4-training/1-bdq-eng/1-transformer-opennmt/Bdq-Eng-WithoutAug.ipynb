{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4003,"status":"ok","timestamp":1707364540394,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"3XsvDNvEzHQ4","outputId":"d702980e-8e42-4890-afd1-54b888c5238f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707364542713,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"WrtjJ7fvzjeM","outputId":"994022b5-1206-4cf3-85fe-8075208db442"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Bahnar-English-Machine-Translation/4-training/1-bdq-eng/1-transformer-opennmt\n"]}],"source":["%cd /content/drive/MyDrive/Bahnar-English-Machine-Translation/4-training/1-bdq-eng/1-transformer-opennmt"]},{"cell_type":"markdown","metadata":{"id":"pzXdIA3KAhlb"},"source":["### Train a Subwording Model\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6968,"status":"ok","timestamp":1707364551409,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"FhX9ArmcE7e8","outputId":"90a02e40-1e50-49e2-a302-3642fe708892"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"J71TLea4E_kX","executionInfo":{"status":"ok","timestamp":1707364551410,"user_tz":-420,"elapsed":15,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"}}},"outputs":[],"source":["import sentencepiece as spm"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"G18aGoGPFCzG","executionInfo":{"status":"ok","timestamp":1707364551410,"user_tz":-420,"elapsed":14,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"}}},"outputs":[],"source":["train_source_file_tok = \"/content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.train.bdq\"\n","train_target_file_tok = \"/content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.train.eng\""]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2258,"status":"ok","timestamp":1707364553655,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"SHz4-YYVAlLQ","outputId":"1051bcb2-bc62-4734-ffed-8bb3be75ee7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Done, training a SentencepPiece model for the Source finished successfully!\n"]}],"source":["source_train_value = '--input='+train_source_file_tok+' --model_prefix=2-subwording-model/bdq-source --vocab_size=14000 --hard_vocab_limit=false --model_type=bpe --split_digits=true'\n","spm.SentencePieceTrainer.train(source_train_value)\n","print(\"Done, training a SentencepPiece model for the Source finished successfully!\")"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1707364553656,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"8Jxvkag_ospF","outputId":"6dbcbdb9-691c-4f15-a060-9b48294f1ba7"},"outputs":[{"output_type":"stream","name":"stdout","text":["['▁Đawit', '▁apinh', '▁dơ̆ng', ':', '▁Lu', '▁kon', '▁pơlei', '▁Kêila', '▁gô', '▁jao', '▁inh', '▁păng', '▁lu', '▁bơngai', '▁kiơ̆', '▁inh', '▁lăm', '▁tơpang', '▁ti', '▁Sôl', '▁hă']\n"]}],"source":["example = \"Đawit apinh dơ̆ng: Lu kon pơlei Kêila gô jao inh păng lu bơngai kiơ̆ inh lăm tơpang ti Sôl hă\"\n","source_model = \"2-subwording-model/bdq-source.model\"\n","sp = spm.SentencePieceProcessor()\n","sp.load(source_model)\n","print(sp.encode_as_pieces(example))"]},{"cell_type":"code","source":["!python /content/drive/MyDrive/Bahnar-English-Machine-Translation/2-data-processing/subwording/2-subword.py 2-subwording-model/bdq-source.model /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.train.bdq 1-subworded-data/bdq-eng.train.subword.bdq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AlaAz73V2lZI","executionInfo":{"status":"ok","timestamp":1707364641143,"user_tz":-420,"elapsed":1541,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"}},"outputId":"fa8efaaf-4194-4854-dd61-631536dac62c"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: 2-subwording-model/bdq-source.model\n","Dataset: /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.train.bdq\n","Done subwording the file! Output: 1-subworded-data/bdq-eng.train.subword.bdq\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/Bahnar-English-Machine-Translation/2-data-processing/subwording/2-subword.py 2-subwording-model/bdq-source.model /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.val.bdq 1-subworded-data/bdq-eng.val.subword.bdq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ity4t-c63Pup","executionInfo":{"status":"ok","timestamp":1707364666891,"user_tz":-420,"elapsed":1334,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"}},"outputId":"351e8b2a-467a-4249-d4ad-753487a3dcbe"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: 2-subwording-model/bdq-source.model\n","Dataset: /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.val.bdq\n","Done subwording the file! Output: 1-subworded-data/bdq-eng.val.subword.bdq\n"]}]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":749,"status":"ok","timestamp":1707364677059,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"5bJ7eQbGktC-","outputId":"5a49f818-39c3-4dcb-ca34-97d3e5b85767"},"outputs":[{"output_type":"stream","name":"stdout","text":["▁kon ▁sâu ▁Nêsia , ▁Hatipha\n","▁Athei ▁ăn ▁kơ ▁lu ▁sư ▁băt ▁tôm ▁yoch ▁kơnê̆ ▁krưp ▁sư\n","▁Sư ▁rơih ▁mơjĭt -' bar ▁' nu ▁bơngai ▁wă ▁oei ▁hơdai ▁Sư ▁păng ▁wă ▁kơ ▁Sư ▁chă ▁wơh ▁năm ▁bơtho\n","▁Ăn ▁tơdrong ▁ư - ang ▁Ih ▁tơ ▁jơ̆p ▁kơpal ▁teh ▁đak\n","▁Lu ▁' bok ▁soi ▁tung ▁tơmơ̆t ▁Hom ▁Pơgơ̆p ▁Kră ▁Yang ▁tơ ▁lăm ▁anih ▁' măn ▁lê̆ ▁kơ ▁Hom ▁Pơgơ̆p , ▁tơ ▁anih ▁' Lơ̆ng ▁Rơgoh ▁Hloh ▁lăm ▁hnam ▁Kră ▁Yang ▁' Bok ▁Kei - Dei , ▁tơ ▁ala ▁lu ▁pơnăr ▁rup ▁chêrubim\n","▁Bu ▁hơtŭt ▁' bơm ▁dôm ▁tơmam ▁noh ▁jing ▁kơnê̆ ▁' mê̆ -' mach ▁truh ▁kơmăng , ▁ưh ▁kơ ▁gơh ▁sa ▁tơmam ▁đe ▁' măn ▁lê̆ ▁rơgoh ▁mă - lei ▁đang ▁kơ ▁hum ▁lăm ▁đak\n","▁Thoi ▁noh ▁Naaman ▁mơ̆t ▁roi ▁kơ ▁pơtao , ▁yŏng ▁tơ ' ngla ▁sư ▁dôm ▁nơ̆r ▁drŏ - kăn ▁' lơ̆p ▁bơngai ▁Isơrael\n","▁Năr ▁mă ▁tơdrâu ▁lu ▁iĕm ▁athei ▁pơyơ̆r ▁tơhngam ▁tŏ ▁rơmo ▁dăm , ▁' bar ▁tŏ ▁triu ▁tơno , ▁mơjĭt - puăn ▁tŏ ▁kon ▁triu ▁tơno ▁' nao ▁minh ▁sơnăm , ▁huay ▁kơ ▁jĭ ▁kiơ\n","▁“ Inh ▁gô ▁tuh ▁Yang ▁Bơhngol ▁tơdrong ▁pŭn ▁hiôk ▁păng ▁tơdrong ▁krao ▁apinh ▁kơ ▁hnam ▁Đawit ▁păng ▁kơ ▁lu ▁kon ▁pơlei ▁Jêrusalem ; ▁lu ▁sư ▁gô ▁lăng ▁tơ ▁Inh ▁jơ̆ ▁Kră ▁Yang ▁mă ▁đêl ▁lu ▁sư ▁' bet ▁boih ; ▁păng ▁lu ▁sư ▁gô ▁nhơ̆m ▁hmoi , ▁nhơ̆m ▁hmoi ▁thoi ▁' mêm ▁kơ ▁kon ▁dăm ▁lôch , ▁lu ▁sư ▁gô ▁oei ▁lăm ▁tơdrong ▁chhŭr ▁nuih , ▁thoi ▁lu ▁bơngai ▁mă ▁đei ▁tơdrong ▁chhŭr ▁nuih ▁ơh ▁sơ ' ngon ▁yua ▁kơ ▁kon ▁kơdră ▁lu ▁sư ▁hiong\n","▁Kră ▁Yang ▁khan : ▁“ Lăm ▁năr ▁noh , ▁Inh ▁gô ▁tơl ▁tơwih ▁kơ ▁lu ▁tăl ▁plĕnh ▁ăn ▁hơmơ̆l , ▁lu ▁tăl ▁plĕnh ▁gô ▁tơl ▁tơwih ▁kơ ▁teh ▁ăn ▁' mi\n"]}],"source":["!head -n 10 1-subworded-data/bdq-eng.val.subword.bdq"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":856,"status":"ok","timestamp":1707364693787,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"ME7BFhowqhAK","outputId":"8de5a067-abf2-46d4-ed3b-347c22fb359d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Done, training a SentencepPiece model for the Target finished successfully!\n"]}],"source":["target_train_value = '--input='+train_target_file_tok+' --model_prefix=2-subwording-model/eng-target --vocab_size=32000 --hard_vocab_limit=false --model_type=bpe --split_digits=true'\n","spm.SentencePieceTrainer.train(target_train_value)\n","print(\"Done, training a SentencepPiece model for the Target finished successfully!\")"]},{"cell_type":"code","source":["!python /content/drive/MyDrive/Bahnar-English-Machine-Translation/2-data-processing/subwording/2-subword.py 2-subwording-model/eng-target.model /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.train.eng 1-subworded-data/bdq-eng.train.subword.eng"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYI2sR8t3eFy","executionInfo":{"status":"ok","timestamp":1707364745141,"user_tz":-420,"elapsed":1538,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"}},"outputId":"97391e6d-f23d-4b3e-8024-032415ab0e4f"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: 2-subwording-model/eng-target.model\n","Dataset: /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.train.eng\n","Done subwording the file! Output: 1-subworded-data/bdq-eng.train.subword.eng\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/Bahnar-English-Machine-Translation/2-data-processing/subwording/2-subword.py 2-subwording-model/eng-target.model /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.val.eng 1-subworded-data/bdq-eng.val.subword.eng"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ay6pT_4B3o1M","executionInfo":{"status":"ok","timestamp":1707364765089,"user_tz":-420,"elapsed":1399,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"}},"outputId":"874ca85c-e1cf-4fd9-d38b-ec3c1eab4145"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: 2-subwording-model/eng-target.model\n","Dataset: /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/1-train/1-without_aug/train-val-split/bdq-eng.val.eng\n","Done subwording the file! Output: 1-subworded-data/bdq-eng.val.subword.eng\n"]}]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":570,"status":"ok","timestamp":1707364784435,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"9NSosw1LE_A4","outputId":"3d8f1920-6f85-44b1-e5c3-2bf3e66cbd98"},"outputs":[{"output_type":"stream","name":"stdout","text":["▁the ▁children ▁of ▁Neziah , ▁the ▁children ▁of ▁Hatipha\n","▁yea , ▁thou ▁shalt ▁shew ▁her ▁all ▁her ▁abominations\n","▁And ▁he ▁ordained ▁twelve , ▁that ▁they ▁should ▁be ▁with ▁him , ▁and ▁that ▁he ▁might ▁send ▁them ▁forth ▁to ▁preach\n","▁And ▁thy ▁glory ▁above ▁all ▁the ▁earth\n","▁And ▁the ▁priests ▁brought ▁in ▁the ▁ark ▁of ▁the ▁covenant ▁of ▁the ▁LORD ▁unto ▁his ▁place , ▁to ▁the ▁oracle ▁of ▁the ▁house , ▁into ▁the ▁most ▁holy ▁place , ▁even ▁under ▁the ▁wings ▁of ▁the ▁cherubims\n","▁the ▁soul ▁which ▁hath ▁touched ▁any ▁such ▁shall ▁be ▁unclean ▁until ▁even , ▁and ▁shall ▁not ▁eat ▁of ▁the ▁holy ▁things , ▁unless ▁he ▁wash ▁his ▁flesh ▁with ▁water\n","▁And ▁one ▁went ▁in , ▁and ▁told ▁his ▁lord , ▁saying , ▁Thus ▁and ▁thus ▁said ▁the ▁maid ▁that ▁is ▁of ▁the ▁land ▁of ▁Israel\n","▁And ▁on ▁the ▁sixth ▁day ▁eight ▁bullocks , ▁two ▁rams , ▁and ▁fourteen ▁lambs ▁of ▁the ▁first ▁year ▁without ▁blemish\n","▁And ▁I ▁will ▁pour ▁upon ▁the ▁house ▁of ▁David , ▁and ▁upon ▁the ▁inhabitants ▁of ▁Jerusalem , ▁the ▁spirit ▁of ▁grace ▁and ▁of ▁supplications : ▁and ▁they ▁shall ▁look ▁upon ▁me ▁whom ▁they ▁have ▁pierced , ▁and ▁they ▁shall ▁mourn ▁for ▁him , ▁as ▁one ▁mourneth ▁for ▁his ▁only ▁son , ▁and ▁shall ▁be ▁in ▁bitterness ▁for ▁him , ▁as ▁one ▁that ▁is ▁in ▁bitterness ▁for ▁his ▁firstborn\n","▁And ▁it ▁shall ▁come ▁to ▁pass ▁in ▁that ▁day , ▁I ▁will ▁hear , ▁saith ▁the ▁LORD , ▁I ▁will ▁hear ▁the ▁heavens , ▁and ▁they ▁shall ▁hear ▁the ▁earth\n"]}],"source":["!head -n 10 1-subworded-data/bdq-eng.val.subword.eng"]},{"cell_type":"markdown","metadata":{"id":"cBDQy6vCJP4q"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"yMiM14CNJI9H"},"source":["## Training Configuration"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15899,"status":"ok","timestamp":1707364811569,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"BZqWCc0YJRTu","outputId":"4535dbce-0784-4da8-c967-fc06c12b27d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting OpenNMT-py\n","  Downloading OpenNMT_py-3.4.3-py3-none-any.whl (257 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch<2.2,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.0+cu121)\n","Collecting configargparse (from OpenNMT-py)\n","  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n","Collecting ctranslate2<4,>=3.17 (from OpenNMT-py)\n","  Downloading ctranslate2-3.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.15.1)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n","Collecting waitress (from OpenNMT-py)\n","  Downloading waitress-3.0.0-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyonmttok<2,>=1.35 (from OpenNMT-py)\n","  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.1)\n","Collecting sacrebleu (from OpenNMT-py)\n","  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n","  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyahocorasick (from OpenNMT-py)\n","  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fasttext-wheel (from OpenNMT-py)\n","  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.7.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (67.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (1.23.5)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.60.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.5.2)\n","Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2.1.0)\n","Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n","  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n","Collecting portalocker (from sacrebleu->OpenNMT-py)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n","Collecting colorama (from sacrebleu->OpenNMT-py)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.2.2)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=2.0.1->OpenNMT-py) (2.1.5)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (2.16.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy->OpenNMT-py) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy->OpenNMT-py) (0.1.4)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->OpenNMT-py) (0.16.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=2.0.1->OpenNMT-py) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n","Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, OpenNMT-py\n","Successfully installed OpenNMT-py-3.4.3 colorama-0.4.6 configargparse-1.7 ctranslate2-3.24.0 fasttext-wheel-0.9.2 portalocker-2.8.2 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.6.1 sacrebleu-2.4.0 waitress-3.0.0\n"]}],"source":["!pip3 install OpenNMT-py"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"fjdeFaISI5KJ","executionInfo":{"status":"ok","timestamp":1707364904515,"user_tz":-420,"elapsed":686,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"}}},"outputs":[],"source":["# Create the YAML configuration file\n","\n","config = '''# config.yaml\n","\n","\n","## Where the samples will be written\n","save_data: vocabulary\n","\n","# Training files\n","data:\n","    corpus_1:\n","        path_src: 1-subworded-data/bdq-eng.train.subword.bdq\n","        path_tgt: 1-subworded-data/bdq-eng.train.subword.eng\n","        transforms: [filtertoolong]\n","    valid:\n","        path_src: 1-subworded-data/bdq-eng.val.subword.bdq\n","        path_tgt: 1-subworded-data/bdq-eng.val.subword.eng\n","        transforms: [filtertoolong]\n","\n","# Vocabulary files, generated by onmt_build_vocab\n","src_vocab: vocabulary/bdq-source.vocab\n","tgt_vocab: vocabulary/eng-target.vocab\n","\n","# Vocabulary size - should be the same as in sentence piece\n","src_vocab_size: 14000\n","tgt_vocab_size: 32000\n","\n","# Filter out source/target longer than n if [filtertoolong] enabled\n","src_seq_length: 150\n","src_seq_length: 150\n","\n","# Tokenization options\n","src_subword_model: 2-subwording-model/bdq-source.model\n","tgt_subword_model: 2-subwording-model/eng-target.model\n","\n","# Where to save the log file and the output models/checkpoints\n","log_file: train.log\n","save_model: 4-model-checkpoints/baen\n","\n","# Stop training if it does not imporve after n validations\n","early_stopping: 4\n","\n","# Default: 5000 - Save a model checkpoint for each n\n","save_checkpoint_steps: 1000\n","\n","# To save space, limit checkpoints to last n\n","# keep_checkpoint: 3\n","\n","seed: 3435\n","\n","# Default: 100000 - Train the model to max n steps\n","# Increase to 200000 or more for large datasets\n","# For fine-tuning, add up the required steps to the original steps\n","train_steps: 3000\n","\n","# Default: 10000 - Run validation after n steps\n","valid_steps: 1000\n","\n","# Default: 4000 - for large datasets, try up to 8000\n","warmup_steps: 1000\n","report_every: 100\n","\n","# Number of GPUs, and IDs of GPUs\n","world_size: 1\n","gpu_ranks: [0]\n","\n","# Batching\n","bucket_size: 262144\n","num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n","batch_type: \"tokens\"\n","batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n","valid_batch_size: 2048\n","max_generator_batches: 2\n","accum_count: [4]\n","accum_steps: [0]\n","\n","# Optimization\n","model_dtype: \"fp16\"\n","optim: \"adam\"\n","learning_rate: 2\n","# warmup_steps: 8000\n","decay_method: \"noam\"\n","adam_beta2: 0.998\n","max_grad_norm: 0\n","label_smoothing: 0.1\n","param_init: 0\n","param_init_glorot: true\n","normalization: \"tokens\"\n","\n","# Model\n","encoder_type: transformer\n","decoder_type: transformer\n","position_encoding: true\n","enc_layers: 6\n","dec_layers: 6\n","heads: 8\n","hidden_size: 512\n","word_vec_size: 512\n","transformer_ff: 2048\n","dropout_steps: [0]\n","dropout: [0.1]\n","attention_dropout: [0.1]\n","'''\n","\n","with open(\"config.yaml\", \"w+\") as config_yaml:\n","  config_yaml.write(config)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":783,"status":"ok","timestamp":1707364907842,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"wrwYg19WKGOE","outputId":"9261b93a-851d-4425-cf18-1f3fbb1adec8"},"outputs":[{"output_type":"stream","name":"stdout","text":["# config.yaml\n","\n","\n","## Where the samples will be written\n","save_data: vocabulary\n","\n","# Training files\n","data:\n","    corpus_1:\n","        path_src: 1-subworded-data/bdq-eng.train.subword.bdq\n","        path_tgt: 1-subworded-data/bdq-eng.train.subword.eng\n","        transforms: [filtertoolong]\n","    valid:\n","        path_src: 1-subworded-data/bdq-eng.val.subword.bdq\n","        path_tgt: 1-subworded-data/bdq-eng.val.subword.eng\n","        transforms: [filtertoolong]\n","\n","# Vocabulary files, generated by onmt_build_vocab\n","src_vocab: vocabulary/bdq-source.vocab\n","tgt_vocab: vocabulary/eng-target.vocab\n","\n","# Vocabulary size - should be the same as in sentence piece\n","src_vocab_size: 14000\n","tgt_vocab_size: 32000\n","\n","# Filter out source/target longer than n if [filtertoolong] enabled\n","src_seq_length: 150\n","src_seq_length: 150\n","\n","# Tokenization options\n","src_subword_model: 2-subwording-model/bdq-source.model\n","tgt_subword_model: 2-subwording-model/eng-target.model\n","\n","# Where to save the log file and the output models/checkpoints\n","log_file: train.log\n","save_model: 4-model-checkpoints/baen\n","\n","# Stop training if it does not imporve after n validations\n","early_stopping: 4\n","\n","# Default: 5000 - Save a model checkpoint for each n\n","save_checkpoint_steps: 1000\n","\n","# To save space, limit checkpoints to last n\n","# keep_checkpoint: 3\n","\n","seed: 3435\n","\n","# Default: 100000 - Train the model to max n steps\n","# Increase to 200000 or more for large datasets\n","# For fine-tuning, add up the required steps to the original steps\n","train_steps: 3000\n","\n","# Default: 10000 - Run validation after n steps\n","valid_steps: 1000\n","\n","# Default: 4000 - for large datasets, try up to 8000\n","warmup_steps: 1000\n","report_every: 100\n","\n","# Number of GPUs, and IDs of GPUs\n","world_size: 1\n","gpu_ranks: [0]\n","\n","# Batching\n","bucket_size: 262144\n","num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n","batch_type: \"tokens\"\n","batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n","valid_batch_size: 2048\n","max_generator_batches: 2\n","accum_count: [4]\n","accum_steps: [0]\n","\n","# Optimization\n","model_dtype: \"fp16\"\n","optim: \"adam\"\n","learning_rate: 2\n","# warmup_steps: 8000\n","decay_method: \"noam\"\n","adam_beta2: 0.998\n","max_grad_norm: 0\n","label_smoothing: 0.1\n","param_init: 0\n","param_init_glorot: true\n","normalization: \"tokens\"\n","\n","# Model\n","encoder_type: transformer\n","decoder_type: transformer\n","position_encoding: true\n","enc_layers: 6\n","dec_layers: 6\n","heads: 8\n","hidden_size: 512\n","word_vec_size: 512\n","transformer_ff: 2048\n","dropout_steps: [0]\n","dropout: [0.1]\n","attention_dropout: [0.1]\n"]}],"source":["!cat config.yaml"]},{"cell_type":"markdown","metadata":{"id":"-Pbml6meKRu8"},"source":["## Build Vocab"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":699,"status":"ok","timestamp":1707364911842,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"b8MnN-vpKJX3","outputId":"4d8a1117-a76a-47a0-e044-a8ca7edaf148"},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}],"source":["!nproc --all"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9865,"status":"ok","timestamp":1707364922407,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"MvHTKYRBKU6m","outputId":"83d15280-45e0-4a68-e7a9-3ed562aea124"},"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2024-02-08 04:01:57,979 INFO] Counter vocab from -1 samples.\n","[2024-02-08 04:01:57,979 INFO] n_sample=-1: Build vocab on full datasets.\n","[2024-02-08 04:01:59,331 INFO] Counters src: 6053\n","[2024-02-08 04:01:59,332 INFO] Counters tgt: 9838\n"]}],"source":["!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1707364922408,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"eoVIURQOLAnp","outputId":"c58b4f3d-96e9-4835-b68c-a5e696030774"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-761b9cec-4716-c3d5-87bb-557aceba6536)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2116,"status":"ok","timestamp":1707364924516,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"9KU7JotMKed4","outputId":"2811fbb7-4da7-4831-fa8c-9e8e1bd3dd50"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","Tesla T4\n","Free GPU memory: 14999.0625 out of: 15102.0625\n"]}],"source":["import torch\n","\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))\n","\n","gpu_memory = torch.cuda.mem_get_info(0)\n","print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"]},{"cell_type":"markdown","metadata":{"id":"ZlcEIP4lLXP0"},"source":["## Training"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12858,"status":"ok","timestamp":1707364939448,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"-1wk3A4TLacd","outputId":"093fb75b-127b-4379-e425-0701f75554bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-02-08 04:02:10,160 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2024-02-08 04:02:10,162 INFO] Parsed 2 corpora from -data.\n","[2024-02-08 04:02:10,162 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2024-02-08 04:02:10,199 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '▁kơ', \"▁'\", '▁lu', '▁sư', '-']\n","[2024-02-08 04:02:10,199 INFO] The decoder start token is: <s>\n","[2024-02-08 04:02:10,200 INFO] Building model...\n","[2024-02-08 04:02:10,945 INFO] Switching model to float32 for amp/apex_amp\n","[2024-02-08 04:02:10,945 INFO] Non quantized layer compute is fp16\n","[2024-02-08 04:02:11,151 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(6064, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-5): 6 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(9848, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-5): 6 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=512, out_features=9848, bias=True)\n",")\n","[2024-02-08 04:02:11,156 INFO] encoder: 21992448\n","[2024-02-08 04:02:11,157 INFO] decoder: 35279480\n","[2024-02-08 04:02:11,157 INFO] * number of parameters: 57271928\n","[2024-02-08 04:02:11,158 INFO] Trainable parameters = {'torch.float32': 57271928, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2024-02-08 04:02:11,158 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2024-02-08 04:02:11,158 INFO]  * src vocab size = 6064\n","[2024-02-08 04:02:11,158 INFO]  * tgt vocab size = 9848\n","[2024-02-08 04:02:11,627 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2024-02-08 04:02:11,628 INFO] Starting training on GPU: [0]\n","[2024-02-08 04:02:11,628 INFO] Start training loop and validate every 1000 steps...\n","[2024-02-08 04:02:11,628 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2024-02-08 04:02:13,184 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2024-02-08 04:02:14,353 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2024-02-08 04:02:15,387 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 4\n","[2024-02-08 04:02:16,398 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 5\n","[2024-02-08 04:02:17,097 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 6\n","^C\n"]}],"source":["!onmt_train -config config.yaml"]},{"cell_type":"markdown","metadata":{"id":"L9X1d4orL0ko"},"source":["# Translation"]},{"cell_type":"code","source":["!pip3 install ctranslate2"],"metadata":{"id":"6waiYTd94eyK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ct2-opennmt-py-converter --model_path 4-model-checkpoints/baen_step_3000.pt --output_dir 4-model-checkpoints/baen_ctranslate2 --quantization int8"],"metadata":{"id":"46HlIA__4iMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/drive/MyDrive/bdq-mt/evaluation/translate.py  /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/2-test/bdq-eng.test.bdq 5-model-prediction/bdq-eng.test.bdq.translated.eng  2-subwording-model/bdq-source.model 2-subwording-model/eng-target.model 4-model-checkpoints/baen_ctranslate2"],"metadata":{"id":"ZYtKuXYl4nbD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head -n 5 5-model-prediction/bdq-eng.test.bdq.translated.eng"],"metadata":{"id":"YFoNYDAN4vVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head -n 5 /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/2-test/bdq-eng.test.eng"],"metadata":{"id":"l_le3ScP4vz0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IAltMCfWL1zq"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11160,"status":"ok","timestamp":1706461752938,"user":{"displayName":"Chi Phan","userId":"10787304499643678585"},"user_tz":-420},"id":"w3z8gmYDN4Xu","outputId":"7c0087ac-e17e-4fec-980f-f65dd2a36bcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sacrebleu\n","  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m769.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n","Installing collected packages: portalocker, colorama, sacrebleu\n","Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.0\n"]}],"source":["!pip3 install sacrebleu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0zJ6P_9iBXT"},"outputs":[],"source":["!python3 /content/drive/MyDrive/bdq-mt/evaluation/eval-metrics.py /content/drive/MyDrive/Bahnar-English-Machine-Translation/3-dataset/bdq-eng/2-test/bdq-eng.test.eng 5-model-prediction/bdq-eng.test.bdq.translated.eng"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1ilQzkQS55YICq4mX7Rz3j3IRGwedz3n5","timestamp":1706350962243}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}