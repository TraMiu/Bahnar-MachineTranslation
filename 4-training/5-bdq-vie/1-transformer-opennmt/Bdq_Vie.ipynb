{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XsvDNvEzHQ4",
        "outputId": "2fbce22b-4e85-477d-b4e5-b76eb73c9aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/drive/MyDrive/bdq-mt/bdq-vie-mt\n",
        "%cd /content/drive/MyDrive/bdq-mt/bdq-vie-mt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrtjJ7fvzjeM",
        "outputId": "7f4fe693-c7b0-43d1-d64b-b8add308c641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/bdq-mt/bdq-vie-mt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "BbXe-TiWzt0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Filtering\n",
        "*   Deleting empty rows;\n",
        "*   Deleting duplicates;\n",
        "*   Deleting source-copied rows;\n",
        "*   Deleting too long Source/Target (ratio 200% and > 200 words);\n",
        "*   Removing HTML;\n",
        "*   Segments will remain in the true-case unless lower is True;\n",
        "*   Shuffling rows"
      ],
      "metadata": {
        "id": "cstEvPilzrLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/filtering/filter.py /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie bdq vie"
      ],
      "metadata": {
        "id": "vLz5s17Iz54L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935d1117-bf90-40af-d31c-90df3576b240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape (rows, columns): (35750, 2)\n",
            "--- Rows with Empty Cells Deleted\t--> Rows: 35750\n",
            "--- Duplicates Deleted\t\t\t--> Rows: 35693\n",
            "--- Source-Copied Rows Deleted\t\t--> Rows: 35591\n",
            "--- Too Long Source/Target Deleted\t--> Rows: 34975\n",
            "--- HTML Removed\t\t\t--> Rows: 34975\n",
            "--- Rows will remain in true-cased\t--> Rows: 34975\n",
            "--- Rows with Empty Cells Deleted\t--> Rows: 34975\n",
            "--- Rows Shuffled\t\t\t--> Rows: 34975\n",
            "--- Source Saved: /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq\n",
            "--- Target Saved: /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 3 /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq && echo \"-----\" && head -n 3 /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQd3XP8i0Y9I",
        "outputId": "425458f9-8618-4a62-a16a-f1e81233f835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kră Yang gô ăn kơ iĕm pŭn hiôk tơ jơ̆p-jang anih, tơ lăm pơlei dah tơ mir chŭn\n",
            "Ih yua tơdrong mơsêh pơjing lu kông gei kơjăp,\n",
            "atau\n",
            "-----\n",
            "Chúa sẽ ban phước cho anh chị em ở khắp mọi nơi, trong thành thị cũng như ngoài đồng ruộng\n",
            "Ngài dùng quyền năng thiết lập núi non,\n",
            "đứng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "E36VEXkYHrNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/train_dev_split/tran_dev_test_split.py 2000 2000 /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq /content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZjTcuf2IHnc",
        "outputId": "b52169cb-59d1-4ef9-ef33-ef48ff2acf9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape: (34975, 2)\n",
            "--- Empty Cells Deleted --> Rows: 34975\n",
            "--- Wrote Files\n",
            "Done!\n",
            "Output files\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq.train\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie.train\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq.eval\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie.eval\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq.test\n",
            "/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.vie-filtered.vie.test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n"
      ],
      "metadata": {
        "id": "VY09Oss50IEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a Subwording Model\n"
      ],
      "metadata": {
        "id": "pzXdIA3KAhlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhX9ArmcE7e8",
        "outputId": "41a92ba7-695e-4175-bc95-f8b40293419c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "J71TLea4E_kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_source_file_tok = \"/content/drive/MyDrive/bdq-mt/dataset/bdq-vie/all.vie-bdq.bdq-filtered.bdq.train\"\n",
        "train_target_file_tok = \"/content/drive/MyDrive/bdq-mt/bdq-vie-mt/data/all.vie-bdq.vie-filtered.vie.train\""
      ],
      "metadata": {
        "id": "G18aGoGPFCzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_train_value = '--input='+train_source_file_tok+' --model_prefix=subwording/source --vocab_size=14000 --hard_vocab_limit=false --model_type=bpe --split_digits=true'\n",
        "spm.SentencePieceTrainer.train(source_train_value)\n",
        "print(\"Done, training a SentencepPiece model for the Source finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHz4-YYVAlLQ",
        "outputId": "f2d8bfd9-1577-49a8-dac7-fef986db47c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done, training a SentencepPiece model for the Source finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/subwording/2-subword.py subwording/source.model data/all.vie-bdq.bdq-filtered.bdq.train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4vUV7UoGEPC",
        "outputId": "6061a8ff-8dcb-4579-d070-64263087304f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: subwording/source.model\n",
            "Dataset: data/all.vie-bdq.bdq-filtered.bdq.train\n",
            "Done subwording the file! Output: data/all.vie-bdq.bdq-filtered.bdq.train.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/subwording/2-subword.py subwording/source.model data/all.vie-bdq.bdq-filtered.bdq.eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRBPN_mIJKk9",
        "outputId": "48ca755d-f47f-4b05-ee8f-d9c2b8b1394b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: subwording/source.model\n",
            "Dataset: data/all.vie-bdq.bdq-filtered.bdq.eval\n",
            "Done subwording the file! Output: data/all.vie-bdq.bdq-filtered.bdq.eval.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_train_value = '--input='+train_target_file_tok+' --model_prefix=subwording/target --vocab_size=32000 --hard_vocab_limit=false --model_type=bpe --split_digits=true'\n",
        "spm.SentencePieceTrainer.train(target_train_value)\n",
        "print(\"Done, training a SentencepPiece model for the Target finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu4QanegFdYj",
        "outputId": "2d419061-da4a-4fc7-9bec-3b101249ac40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done, training a SentencepPiece model for the Target finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/subwording/2-subword.py subwording/target.model data/all.vie-bdq.vie-filtered.vie.train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1YBD1GuJU82",
        "outputId": "cb414406-8f4e-47e6-9f1c-7d0b3fa19058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: subwording/target.model\n",
            "Dataset: data/all.vie-bdq.vie-filtered.vie.train\n",
            "Done subwording the file! Output: data/all.vie-bdq.vie-filtered.vie.train.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/data-processing/subwording/2-subword.py subwording/target.model data/all.vie-bdq.vie-filtered.vie.eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7InkhscaJeQK",
        "outputId": "0289237d-8298-487d-8806-abb3d938f581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: subwording/target.model\n",
            "Dataset: data/all.vie-bdq.vie-filtered.vie.eval\n",
            "Done subwording the file! Output: data/all.vie-bdq.vie-filtered.vie.eval.subword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 3 data/all.vie-bdq.bdq-filtered.bdq.train.subword && echo \"-----\" && head -n 3 data/all.vie-bdq.vie-filtered.vie.train.subword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V80YyjPGHTe-",
        "outputId": "115300c7-223a-4265-c144-c961808e4d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁Kră ▁Yang ▁gô ▁ăn ▁kơ ▁iĕm ▁pŭn ▁hiôk ▁tơ ▁jơ̆p - jang ▁anih , ▁tơ ▁lăm ▁pơlei ▁dah ▁tơ ▁mir ▁chŭn\n",
            "▁Ih ▁yua ▁tơdrong ▁mơsêh ▁pơjing ▁lu ▁kông ▁gei ▁kơjăp ,\n",
            "▁atau\n",
            "-----\n",
            "▁Chúa ▁sẽ ▁ban ▁phước ▁cho ▁anh ▁chị ▁em ▁ở ▁khắp ▁mọi ▁nơi , ▁trong ▁thành ▁thị ▁cũng ▁như ▁ngoài ▁đồng ▁ruộng\n",
            "▁Ngài ▁dùng ▁quyền ▁năng ▁thiết ▁lập ▁núi ▁non ,\n",
            "▁đứng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained tokenization for Vietnamese Using VNCoreNLP word segmenter and PhoBert Tokenizer\n"
      ],
      "metadata": {
        "id": "t-z2YfApAcCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py_vncorenlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-8fy6ml0Qxy",
        "outputId": "4389d9bb-d4a1-440d-8b47-4216daad2f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py_vncorenlp\n",
            "  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius (from py_vncorenlp)\n",
            "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: py_vncorenlp\n",
            "  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4307 sha256=e6d4568f3c6f73d401653aecacf80aae40a103cc97bd263bb314cf1a80ee0cc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
            "Successfully built py_vncorenlp\n",
            "Installing collected packages: pyjnius, py_vncorenlp\n",
            "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import py_vncorenlp\n",
        "\n",
        "# Automatically download VnCoreNLP components from the original repository\n",
        "# and save them in some local machine folder\n",
        "py_vncorenlp.download_model(save_dir='/content/drive/MyDrive/bdq-vie-mt/vncorenlp')"
      ],
      "metadata": {
        "id": "YXfU1Ddn3sjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the word and sentence segmentation component\n",
        "rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/content/drive/MyDrive/bdq-vie-mt/vncorenlp')"
      ],
      "metadata": {
        "id": "oijyFMla4u0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Công tác phòng chống tội phạm về kinh tế, ma túy, môi trường được tăng cường triển khai, thực hiện đạt kết quả\"\n",
        "\n",
        "output = rdrsegmenter.word_segment(text)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnJYE6k27e8u",
        "outputId": "dc04dce5-5832-462d-a7bb-b5aa9f07666d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Công_tác phòng_chống tội_phạm về kinh_tế , ma_tuý , môi_trường được tăng_cường triển_khai , thực_hiện đạt kết_quả']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxAcBad_Az2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "cBDQy6vCJP4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Configuration"
      ],
      "metadata": {
        "id": "yMiM14CNJI9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install OpenNMT-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZqWCc0YJRTu",
        "outputId": "884600a4-8977-4409-8c1f-8a9001f38f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-3.4.3-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.2,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.0+cu121)\n",
            "Collecting configargparse (from OpenNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ctranslate2<4,>=3.17 (from OpenNMT-py)\n",
            "  Downloading ctranslate2-3.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.15.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n",
            "Collecting waitress (from OpenNMT-py)\n",
            "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.35 (from OpenNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.1)\n",
            "Collecting sacrebleu (from OpenNMT-py)\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from OpenNMT-py)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel (from OpenNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2.1.0)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n",
            "Collecting portalocker (from sacrebleu->OpenNMT-py)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->OpenNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.10.14)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=2.0.1->OpenNMT-py) (2.1.4)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy->OpenNMT-py) (0.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=2.0.1->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n",
            "Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, OpenNMT-py\n",
            "Successfully installed OpenNMT-py-3.4.3 colorama-0.4.6 configargparse-1.7 ctranslate2-3.24.0 fasttext-wheel-0.9.2 portalocker-2.8.2 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.6.1 sacrebleu-2.4.0 waitress-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the YAML configuration file\n",
        "# On a regular machine, you can create it manually or with nano\n",
        "# Note here we are using some smaller values because the dataset is small\n",
        "# For larger datasets, consider increasing: train_steps, valid_steps, warmup_steps, save_checkpoint_steps, keep_checkpoint\n",
        "\n",
        "config = '''# config.yaml\n",
        "\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: data/all.vie-bdq.bdq-filtered.bdq.train.subword\n",
        "        path_tgt: data/all.vie-bdq.vie-filtered.vie.train.subword\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: data/all.vie-bdq.bdq-filtered.bdq.eval.subword\n",
        "        path_tgt: data/all.vie-bdq.vie-filtered.vie.eval.subword\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# Vocabulary size - should be the same as in sentence piece\n",
        "src_vocab_size: 14000\n",
        "tgt_vocab_size: 32000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 150\n",
        "src_seq_length: 150\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: subwording/source.model\n",
        "tgt_subword_model: subwording/target.model\n",
        "\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.bdqvie\n",
        "\n",
        "# Stop training if it does not imporve after n validations\n",
        "early_stopping: 4\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 1000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "# keep_checkpoint: 3\n",
        "\n",
        "seed: 3435\n",
        "\n",
        "# Default: 100000 - Train the model to max n steps\n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 3000\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: 1000\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: 1000\n",
        "report_every: 100\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 2048\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 2\n",
        "# warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 8\n",
        "hidden_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ],
      "metadata": {
        "id": "fjdeFaISI5KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrwYg19WKGOE",
        "outputId": "2ab5188e-35ad-410f-b851-7db2fac6abed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# config.yaml\n",
            "\n",
            "\n",
            "## Where the samples will be written\n",
            "save_data: run\n",
            "\n",
            "# Training files\n",
            "data:\n",
            "    corpus_1:\n",
            "        path_src: data/all.vie-bdq.bdq-filtered.bdq.train.subword\n",
            "        path_tgt: data/all.vie-bdq.vie-filtered.vie.train.subword\n",
            "        transforms: [filtertoolong]\n",
            "    valid:\n",
            "        path_src: data/all.vie-bdq.bdq-filtered.bdq.eval.subword\n",
            "        path_tgt: data/all.vie-bdq.vie-filtered.vie.eval.subword\n",
            "        transforms: [filtertoolong]\n",
            "\n",
            "# Vocabulary files, generated by onmt_build_vocab\n",
            "src_vocab: run/source.vocab\n",
            "tgt_vocab: run/target.vocab\n",
            "\n",
            "# Vocabulary size - should be the same as in sentence piece\n",
            "src_vocab_size: 14000\n",
            "tgt_vocab_size: 32000\n",
            "\n",
            "# Filter out source/target longer than n if [filtertoolong] enabled\n",
            "src_seq_length: 150\n",
            "src_seq_length: 150\n",
            "\n",
            "# Tokenization options\n",
            "src_subword_model: subwording/source.model\n",
            "tgt_subword_model: subwording/target.model\n",
            "\n",
            "# Where to save the log file and the output models/checkpoints\n",
            "log_file: train.log\n",
            "save_model: models/model.bdqvie\n",
            "\n",
            "# Stop training if it does not imporve after n validations\n",
            "early_stopping: 4\n",
            "\n",
            "# Default: 5000 - Save a model checkpoint for each n\n",
            "save_checkpoint_steps: 1000\n",
            "\n",
            "# To save space, limit checkpoints to last n\n",
            "# keep_checkpoint: 3\n",
            "\n",
            "seed: 3435\n",
            "\n",
            "# Default: 100000 - Train the model to max n steps\n",
            "# Increase to 200000 or more for large datasets\n",
            "# For fine-tuning, add up the required steps to the original steps\n",
            "train_steps: 3000\n",
            "\n",
            "# Default: 10000 - Run validation after n steps\n",
            "valid_steps: 1000\n",
            "\n",
            "# Default: 4000 - for large datasets, try up to 8000\n",
            "warmup_steps: 1000\n",
            "report_every: 100\n",
            "\n",
            "# Number of GPUs, and IDs of GPUs\n",
            "world_size: 1\n",
            "gpu_ranks: [0]\n",
            "\n",
            "# Batching\n",
            "bucket_size: 262144\n",
            "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
            "batch_type: \"tokens\"\n",
            "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
            "valid_batch_size: 2048\n",
            "max_generator_batches: 2\n",
            "accum_count: [4]\n",
            "accum_steps: [0]\n",
            "\n",
            "# Optimization\n",
            "model_dtype: \"fp16\"\n",
            "optim: \"adam\"\n",
            "learning_rate: 2\n",
            "# warmup_steps: 8000\n",
            "decay_method: \"noam\"\n",
            "adam_beta2: 0.998\n",
            "max_grad_norm: 0\n",
            "label_smoothing: 0.1\n",
            "param_init: 0\n",
            "param_init_glorot: true\n",
            "normalization: \"tokens\"\n",
            "\n",
            "# Model\n",
            "encoder_type: transformer\n",
            "decoder_type: transformer\n",
            "position_encoding: true\n",
            "enc_layers: 6\n",
            "dec_layers: 6\n",
            "heads: 8\n",
            "hidden_size: 512\n",
            "word_vec_size: 512\n",
            "transformer_ff: 2048\n",
            "dropout_steps: [0]\n",
            "dropout: [0.1]\n",
            "attention_dropout: [0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Vocab"
      ],
      "metadata": {
        "id": "-Pbml6meKRu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nproc --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8MnN-vpKJX3",
        "outputId": "078bebbb-7c48-4129-ca73-9f442a31a424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvHTKYRBKU6m",
        "outputId": "a4b5cb5d-30d9-40e3-b2cc-b5b5c9747fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-28 17:43:28.557853: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-28 17:43:28.557908: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-28 17:43:28.559214: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-28 17:43:28.566513: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-28 17:43:29.619611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-28 17:43:31.140182: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 17:43:31.140632: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 17:43:31.140825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2024-01-28 17:43:32,003 INFO] Counter vocab from -1 samples.\n",
            "[2024-01-28 17:43:32,003 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2024-01-28 17:43:33,281 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=6)\n",
            "\n",
            "[2024-01-28 17:43:33,303 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=10)\n",
            "\n",
            "[2024-01-28 17:43:33,338 INFO] Counters src: 11994\n",
            "[2024-01-28 17:43:33,338 INFO] Counters tgt: 7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoVIURQOLAnp",
        "outputId": "fe3f7aa3-6920-47e0-8985-fffe5983fc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-c866bbec-eb3f-7495-f250-d505dad12e43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "gpu_memory = torch.cuda.mem_get_info(0)\n",
        "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KU7JotMKed4",
        "outputId": "1ecd6f3d-f4ba-477d-c65e-4744de1b7af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n",
            "Free GPU memory: 14999.0625 out of: 15102.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ZlcEIP4lLXP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_train -config config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1wk3A4TLacd",
        "outputId": "75ae631e-522b-4f04-d0d8-9f99accbe7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-28 17:43:40.811513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-28 17:43:40.811559: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-28 17:43:40.812785: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-28 17:43:40.819864: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-28 17:43:41.895616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-28 17:43:43.394083: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 17:43:43.394646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 17:43:43.394898: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2024-01-28 17:43:44,160 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2024-01-28 17:43:44,388 INFO] Parsed 2 corpora from -data.\n",
            "[2024-01-28 17:43:44,389 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2024-01-28 17:43:44,433 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', \"▁'\", '▁kơ', '▁tơdrong', '▁sư', '▁']\n",
            "[2024-01-28 17:43:44,433 INFO] The decoder start token is: <s>\n",
            "[2024-01-28 17:43:44,433 INFO] Building model...\n",
            "[2024-01-28 17:43:45,137 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2024-01-28 17:43:45,138 INFO] Non quantized layer compute is fp16\n",
            "[2024-01-28 17:43:45,434 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(12000, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(7904, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=512, out_features=7904, bias=True)\n",
            ")\n",
            "[2024-01-28 17:43:45,438 INFO] encoder: 25031680\n",
            "[2024-01-28 17:43:45,438 INFO] decoder: 33286880\n",
            "[2024-01-28 17:43:45,438 INFO] * number of parameters: 58318560\n",
            "[2024-01-28 17:43:45,439 INFO] Trainable parameters = {'torch.float32': 58318560, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-01-28 17:43:45,439 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-01-28 17:43:45,439 INFO]  * src vocab size = 12000\n",
            "[2024-01-28 17:43:45,440 INFO]  * tgt vocab size = 7904\n",
            "[2024-01-28 17:43:45,821 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2024-01-28 17:43:45,822 INFO] Starting training on GPU: [0]\n",
            "[2024-01-28 17:43:45,822 INFO] Start training loop and validate every 1000 steps...\n",
            "[2024-01-28 17:43:45,822 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n",
            "[2024-01-28 17:43:47,385 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2024-01-28 17:43:48,458 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2024-01-28 17:43:50,540 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2024-01-28 17:43:52,904 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2024-01-28 17:43:54,699 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2024-01-28 17:43:56,628 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2024-01-28 17:43:57,696 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2024-01-28 17:43:59,584 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2024-01-28 17:44:46,136 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 17:44:46,137 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2024-01-28 17:44:47,122 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2024-01-28 17:44:48,094 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2024-01-28 17:44:51,668 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2024-01-28 17:44:52,888 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2024-01-28 17:44:54,904 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2024-01-28 17:44:56,827 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2024-01-28 17:45:01,928 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2024-01-28 17:45:30,222 INFO] Step 100/ 3000; acc: 7.8; ppl: 1783.0; xent: 7.5; lr: 0.00028; sents:   60717; bsz: 3021/3180/152; 11573/12182 tok/s;    104 sec;\n",
            "[2024-01-28 17:45:48,633 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 17:45:48,633 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2024-01-28 17:45:50,050 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2024-01-28 17:45:54,153 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2024-01-28 17:45:55,548 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2024-01-28 17:45:56,509 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2024-01-28 17:45:57,490 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2024-01-28 17:46:02,301 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2024-01-28 17:46:03,249 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2024-01-28 17:46:04,202 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2024-01-28 17:46:49,746 INFO] Step 200/ 3000; acc: 16.8; ppl: 397.9; xent: 6.0; lr: 0.00056; sents:   58938; bsz: 2985/3125/147; 15017/15721 tok/s;    184 sec;\n",
            "[2024-01-28 17:46:54,845 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=134)\n",
            "\n",
            "[2024-01-28 17:46:54,846 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2024-01-28 17:46:56,748 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2024-01-28 17:46:58,566 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2024-01-28 17:47:00,394 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2024-01-28 17:47:05,141 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2024-01-28 17:47:06,502 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2024-01-28 17:47:07,568 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2024-01-28 17:47:08,540 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2024-01-28 17:48:03,952 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=135)\n",
            "\n",
            "[2024-01-28 17:48:03,952 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2024-01-28 17:48:04,976 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2024-01-28 17:48:05,983 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2024-01-28 17:48:06,982 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2024-01-28 17:48:11,728 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2024-01-28 17:48:12,955 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2024-01-28 17:48:13,930 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2024-01-28 17:48:14,922 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2024-01-28 17:48:19,854 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2024-01-28 17:48:45,857 INFO] Step 300/ 3000; acc: 30.0; ppl: 127.6; xent: 4.8; lr: 0.00084; sents:   60045; bsz: 3024/3177/150; 10419/10946 tok/s;    300 sec;\n",
            "[2024-01-28 17:49:10,112 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 17:49:10,113 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2024-01-28 17:49:11,105 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2024-01-28 17:49:15,536 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2024-01-28 17:49:16,527 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2024-01-28 17:49:18,128 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2024-01-28 17:49:19,714 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2024-01-28 17:49:20,690 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2024-01-28 17:49:25,628 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2024-01-28 17:50:08,716 INFO] Step 400/ 3000; acc: 41.4; ppl:  56.9; xent: 4.0; lr: 0.00112; sents:   58633; bsz: 3034/3174/147; 14644/15323 tok/s;    383 sec;\n",
            "[2024-01-28 17:50:17,375 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 17:50:17,375 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2024-01-28 17:50:22,194 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2024-01-28 17:50:23,189 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2024-01-28 17:50:24,165 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2024-01-28 17:50:25,148 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2024-01-28 17:50:30,554 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2024-01-28 17:50:32,232 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 58\n",
            "[2024-01-28 17:50:33,515 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 59\n",
            "[2024-01-28 17:50:34,473 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 60\n",
            "[2024-01-28 17:51:28,748 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 17:51:28,749 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 61\n",
            "[2024-01-28 17:51:29,889 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 62\n",
            "[2024-01-28 17:51:30,874 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 63\n",
            "[2024-01-28 17:51:31,857 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 64\n",
            "[2024-01-28 17:51:32,815 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 65\n",
            "[2024-01-28 17:51:38,031 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 66\n",
            "[2024-01-28 17:51:39,798 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 67\n",
            "[2024-01-28 17:51:41,208 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 68\n",
            "[2024-01-28 17:52:05,447 INFO] Step 500/ 3000; acc: 52.3; ppl:  30.7; xent: 3.4; lr: 0.00140; sents:   60912; bsz: 3004/3162/152; 10292/10835 tok/s;    500 sec;\n",
            "[2024-01-28 17:52:33,538 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 17:52:33,538 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 69\n",
            "[2024-01-28 17:52:34,547 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 70\n",
            "[2024-01-28 17:52:35,510 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 71\n",
            "[2024-01-28 17:52:39,652 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 72\n",
            "[2024-01-28 17:52:40,609 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 73\n",
            "[2024-01-28 17:52:41,786 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 74\n",
            "[2024-01-28 17:52:43,421 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 75\n",
            "[2024-01-28 17:52:44,683 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 76\n",
            "[2024-01-28 17:52:49,521 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 77\n",
            "[2024-01-28 17:53:25,448 INFO] Step 600/ 3000; acc: 59.9; ppl:  20.1; xent: 3.0; lr: 0.00168; sents:   59429; bsz: 2999/3143/149; 14993/15717 tok/s;    580 sec;\n",
            "[2024-01-28 17:53:38,897 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=133)\n",
            "\n",
            "[2024-01-28 17:53:38,897 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 78\n",
            "[2024-01-28 17:53:39,859 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 79\n",
            "[2024-01-28 17:53:43,854 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 80\n",
            "[2024-01-28 17:53:44,838 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 81\n",
            "[2024-01-28 17:53:45,924 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 82\n",
            "[2024-01-28 17:53:47,570 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 83\n",
            "[2024-01-28 17:53:52,543 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 84\n",
            "[2024-01-28 17:53:53,494 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 85\n",
            "[2024-01-28 17:54:46,589 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=138)\n",
            "\n",
            "[2024-01-28 17:54:46,590 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 86\n",
            "[2024-01-28 17:54:47,584 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 87\n",
            "[2024-01-28 17:54:48,551 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 88\n",
            "[2024-01-28 17:54:49,552 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 89\n",
            "[2024-01-28 17:54:50,524 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 90\n",
            "[2024-01-28 17:54:55,280 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 91\n",
            "[2024-01-28 17:54:56,251 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 92\n",
            "[2024-01-28 17:54:57,279 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 93\n",
            "[2024-01-28 17:54:58,236 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 94\n",
            "[2024-01-28 17:55:20,236 INFO] Step 700/ 3000; acc: 65.9; ppl:  15.0; xent: 2.7; lr: 0.00196; sents:   60275; bsz: 3036/3185/151; 10579/11101 tok/s;    694 sec;\n",
            "[2024-01-28 17:55:52,846 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=133)\n",
            "\n",
            "[2024-01-28 17:55:52,847 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 95\n",
            "[2024-01-28 17:55:53,856 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 96\n",
            "[2024-01-28 17:55:54,961 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 97\n",
            "[2024-01-28 17:55:56,608 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 98\n",
            "[2024-01-28 17:56:01,880 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 99\n",
            "[2024-01-28 17:56:02,881 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 100\n",
            "[2024-01-28 17:56:03,848 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 101\n",
            "[2024-01-28 17:56:04,798 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 102\n",
            "[2024-01-28 17:56:39,142 INFO] Step 800/ 3000; acc: 70.0; ppl:  12.2; xent: 2.5; lr: 0.00224; sents:   59278; bsz: 3012/3157/148; 15269/16002 tok/s;    773 sec;\n",
            "[2024-01-28 17:56:56,375 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=135)\n",
            "\n",
            "[2024-01-28 17:56:56,375 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 103\n",
            "[2024-01-28 17:56:57,407 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 104\n",
            "[2024-01-28 17:56:58,864 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 105\n",
            "[2024-01-28 17:57:03,851 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 106\n",
            "[2024-01-28 17:57:04,845 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 107\n",
            "[2024-01-28 17:57:05,832 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 108\n",
            "[2024-01-28 17:57:06,825 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 109\n",
            "[2024-01-28 17:57:11,593 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 110\n",
            "[2024-01-28 17:57:12,544 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 111\n",
            "[2024-01-28 17:57:59,690 INFO] Step 900/ 3000; acc: 72.4; ppl:  10.9; xent: 2.4; lr: 0.00252; sents:   59987; bsz: 2995/3154/150; 14872/15661 tok/s;    854 sec;\n",
            "[2024-01-28 17:58:02,291 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 17:58:02,292 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 112\n",
            "[2024-01-28 17:58:06,862 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 113\n",
            "[2024-01-28 17:58:07,832 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 114\n",
            "[2024-01-28 17:58:08,816 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 115\n",
            "[2024-01-28 17:58:13,356 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 116\n",
            "[2024-01-28 17:58:14,319 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 117\n",
            "[2024-01-28 17:58:15,285 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 118\n",
            "[2024-01-28 17:58:16,253 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 119\n",
            "[2024-01-28 17:59:11,783 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 17:59:11,783 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 120\n",
            "[2024-01-28 17:59:12,799 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 121\n",
            "[2024-01-28 17:59:13,808 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 122\n",
            "[2024-01-28 17:59:14,786 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 123\n",
            "[2024-01-28 17:59:19,124 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 124\n",
            "[2024-01-28 17:59:20,108 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 125\n",
            "[2024-01-28 17:59:21,340 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 126\n",
            "[2024-01-28 17:59:23,020 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 127\n",
            "[2024-01-28 17:59:56,463 INFO] Step 1000/ 3000; acc: 76.3; ppl:   9.2; xent: 2.2; lr: 0.00279; sents:   59721; bsz: 3003/3141/149; 10286/10758 tok/s;    971 sec;\n",
            "[2024-01-28 17:59:57,818 INFO] valid stats calculation\n",
            "                           took: 1.3531405925750732 s.\n",
            "[2024-01-28 17:59:57,820 INFO] Train perplexity: 47.5318\n",
            "[2024-01-28 17:59:57,820 INFO] Train accuracy: 49.2544\n",
            "[2024-01-28 17:59:57,820 INFO] Sentences processed: 597935\n",
            "[2024-01-28 17:59:57,820 INFO] Average bsz: 3011/3160/149\n",
            "[2024-01-28 17:59:57,820 INFO] Validation perplexity: 27.3657\n",
            "[2024-01-28 17:59:57,821 INFO] Validation accuracy: 60.2551\n",
            "[2024-01-28 17:59:57,821 INFO] Model is improving ppl: inf --> 27.3657.\n",
            "[2024-01-28 17:59:57,821 INFO] Model is improving acc: -inf --> 60.2551.\n",
            "[2024-01-28 17:59:57,828 INFO] Saving checkpoint models/model.bdqvie_step_1000.pt\n",
            "[2024-01-28 18:00:38,993 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:00:38,993 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 128\n",
            "[2024-01-28 18:00:40,586 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 129\n",
            "[2024-01-28 18:00:41,575 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 130\n",
            "[2024-01-28 18:00:42,549 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 131\n",
            "[2024-01-28 18:00:43,523 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 132\n",
            "[2024-01-28 18:00:47,861 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 133\n",
            "[2024-01-28 18:00:48,858 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 134\n",
            "[2024-01-28 18:00:49,837 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 135\n",
            "[2024-01-28 18:00:51,089 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 136\n",
            "[2024-01-28 18:01:42,250 INFO] Step 1100/ 3000; acc: 79.1; ppl:   8.2; xent: 2.1; lr: 0.00266; sents:   61226; bsz: 3013/3173/153; 11393/11997 tok/s;   1076 sec;\n",
            "[2024-01-28 18:01:48,803 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=134)\n",
            "\n",
            "[2024-01-28 18:01:48,804 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 137\n",
            "[2024-01-28 18:01:49,821 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 138\n",
            "[2024-01-28 18:01:50,797 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 139\n",
            "[2024-01-28 18:01:51,761 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 140\n",
            "[2024-01-28 18:01:56,205 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 141\n",
            "[2024-01-28 18:01:57,864 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 142\n",
            "[2024-01-28 18:01:58,833 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 143\n",
            "[2024-01-28 18:01:59,794 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 144\n",
            "[2024-01-28 18:02:52,126 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:02:52,127 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 145\n",
            "[2024-01-28 18:02:53,128 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 146\n",
            "[2024-01-28 18:02:54,111 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 147\n",
            "[2024-01-28 18:02:58,258 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 148\n",
            "[2024-01-28 18:02:59,249 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 149\n",
            "[2024-01-28 18:03:00,866 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 150\n",
            "[2024-01-28 18:03:02,758 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 151\n",
            "[2024-01-28 18:03:08,451 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 152\n",
            "[2024-01-28 18:03:09,445 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 153\n",
            "[2024-01-28 18:03:34,715 INFO] Step 1200/ 3000; acc: 83.7; ppl:   6.8; xent: 1.9; lr: 0.00255; sents:   59005; bsz: 3026/3154/148; 10762/11216 tok/s;   1189 sec;\n",
            "[2024-01-28 18:04:00,626 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=135)\n",
            "\n",
            "[2024-01-28 18:04:00,626 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 154\n",
            "[2024-01-28 18:04:05,743 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 155\n",
            "[2024-01-28 18:04:07,186 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 156\n",
            "[2024-01-28 18:04:08,194 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 157\n",
            "[2024-01-28 18:04:09,180 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 158\n",
            "[2024-01-28 18:04:13,850 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 159\n",
            "[2024-01-28 18:04:14,842 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 160\n",
            "[2024-01-28 18:04:15,830 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 161\n",
            "[2024-01-28 18:05:00,457 INFO] Step 1300/ 3000; acc: 87.6; ppl:   5.9; xent: 1.8; lr: 0.00245; sents:   59363; bsz: 3022/3183/148; 14100/14850 tok/s;   1275 sec;\n",
            "[2024-01-28 18:05:10,766 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:05:10,767 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 162\n",
            "[2024-01-28 18:05:12,293 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 163\n",
            "[2024-01-28 18:05:13,285 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 164\n",
            "[2024-01-28 18:05:14,307 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 165\n",
            "[2024-01-28 18:05:15,293 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 166\n",
            "[2024-01-28 18:05:19,708 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 167\n",
            "[2024-01-28 18:05:20,721 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 168\n",
            "[2024-01-28 18:05:21,716 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 169\n",
            "[2024-01-28 18:05:23,252 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 170\n",
            "[2024-01-28 18:06:20,280 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:06:20,280 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 171\n",
            "[2024-01-28 18:06:21,295 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 172\n",
            "[2024-01-28 18:06:22,306 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 173\n",
            "[2024-01-28 18:06:23,299 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 174\n",
            "[2024-01-28 18:06:27,714 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 175\n",
            "[2024-01-28 18:06:29,011 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 176\n",
            "[2024-01-28 18:06:30,832 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 177\n",
            "[2024-01-28 18:06:32,795 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 178\n",
            "[2024-01-28 18:06:55,472 INFO] Step 1400/ 3000; acc: 89.9; ppl:   5.5; xent: 1.7; lr: 0.00236; sents:   59030; bsz: 2979/3132/148; 10360/10892 tok/s;   1390 sec;\n",
            "[2024-01-28 18:07:25,271 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:07:25,272 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 179\n",
            "[2024-01-28 18:07:26,300 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 180\n",
            "[2024-01-28 18:07:27,313 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 181\n",
            "[2024-01-28 18:07:32,200 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 182\n",
            "[2024-01-28 18:07:33,995 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 183\n",
            "[2024-01-28 18:07:35,712 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 184\n",
            "[2024-01-28 18:07:36,999 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 185\n",
            "[2024-01-28 18:07:41,824 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 186\n",
            "[2024-01-28 18:07:42,830 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 187\n",
            "[2024-01-28 18:08:17,246 INFO] Step 1500/ 3000; acc: 92.0; ppl:   5.1; xent: 1.6; lr: 0.00228; sents:   59958; bsz: 2979/3138/150; 14573/15350 tok/s;   1471 sec;\n",
            "[2024-01-28 18:08:33,437 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=134)\n",
            "\n",
            "[2024-01-28 18:08:33,438 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 188\n",
            "[2024-01-28 18:08:37,724 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 189\n",
            "[2024-01-28 18:08:39,165 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 190\n",
            "[2024-01-28 18:08:40,883 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 191\n",
            "[2024-01-28 18:08:45,592 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 192\n",
            "[2024-01-28 18:08:46,590 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 193\n",
            "[2024-01-28 18:08:47,603 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 194\n",
            "[2024-01-28 18:08:48,598 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 195\n",
            "[2024-01-28 18:09:41,378 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=137)\n",
            "\n",
            "[2024-01-28 18:09:41,378 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 196\n",
            "[2024-01-28 18:09:42,379 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 197\n",
            "[2024-01-28 18:09:43,848 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 198\n",
            "[2024-01-28 18:09:48,608 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 199\n",
            "[2024-01-28 18:09:49,580 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 200\n",
            "[2024-01-28 18:09:50,568 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 201\n",
            "[2024-01-28 18:09:51,543 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 202\n",
            "[2024-01-28 18:09:56,651 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 203\n",
            "[2024-01-28 18:09:58,333 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 204\n",
            "[2024-01-28 18:10:15,326 INFO] Step 1600/ 3000; acc: 93.4; ppl:   4.8; xent: 1.6; lr: 0.00221; sents:   60878; bsz: 3058/3198/152; 10358/10832 tok/s;   1590 sec;\n",
            "[2024-01-28 18:10:50,386 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=133)\n",
            "\n",
            "[2024-01-28 18:10:50,386 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 205\n",
            "[2024-01-28 18:10:54,453 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 206\n",
            "[2024-01-28 18:10:55,475 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 207\n",
            "[2024-01-28 18:10:56,483 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 208\n",
            "[2024-01-28 18:10:57,484 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 209\n",
            "[2024-01-28 18:11:03,023 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 210\n",
            "[2024-01-28 18:11:04,776 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 211\n",
            "[2024-01-28 18:11:06,037 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 212\n",
            "[2024-01-28 18:11:39,027 INFO] Step 1700/ 3000; acc: 94.9; ppl:   4.6; xent: 1.5; lr: 0.00214; sents:   58446; bsz: 3016/3156/146; 14412/15082 tok/s;   1673 sec;\n",
            "[2024-01-28 18:11:57,936 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=137)\n",
            "\n",
            "[2024-01-28 18:11:57,936 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 213\n",
            "[2024-01-28 18:11:58,978 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 214\n",
            "[2024-01-28 18:11:59,968 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 215\n",
            "[2024-01-28 18:12:05,154 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 216\n",
            "[2024-01-28 18:12:06,851 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 217\n",
            "[2024-01-28 18:12:07,911 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 218\n",
            "[2024-01-28 18:12:08,920 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 219\n",
            "[2024-01-28 18:12:09,950 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 220\n",
            "[2024-01-28 18:12:14,915 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 221\n",
            "[2024-01-28 18:13:01,330 INFO] Step 1800/ 3000; acc: 95.3; ppl:   4.5; xent: 1.5; lr: 0.00208; sents:   60097; bsz: 3000/3161/150; 14578/15363 tok/s;   1756 sec;\n",
            "[2024-01-28 18:13:06,016 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=134)\n",
            "\n",
            "[2024-01-28 18:13:06,016 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 222\n",
            "[2024-01-28 18:13:07,054 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 223\n",
            "[2024-01-28 18:13:11,782 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 224\n",
            "[2024-01-28 18:13:13,371 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 225\n",
            "[2024-01-28 18:13:14,390 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 226\n",
            "[2024-01-28 18:13:15,394 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 227\n",
            "[2024-01-28 18:13:20,207 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 228\n",
            "[2024-01-28 18:13:21,207 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 229\n",
            "[2024-01-28 18:14:16,319 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:14:16,319 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 230\n",
            "[2024-01-28 18:14:18,087 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 231\n",
            "[2024-01-28 18:14:19,208 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 232\n",
            "[2024-01-28 18:14:20,220 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 233\n",
            "[2024-01-28 18:14:24,816 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 234\n",
            "[2024-01-28 18:14:25,809 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 235\n",
            "[2024-01-28 18:14:26,815 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 236\n",
            "[2024-01-28 18:14:27,824 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 237\n",
            "[2024-01-28 18:15:00,292 INFO] Step 1900/ 3000; acc: 96.1; ppl:   4.4; xent: 1.5; lr: 0.00203; sents:   62213; bsz: 3009/3163/156; 10118/10634 tok/s;   1874 sec;\n",
            "[2024-01-28 18:15:23,437 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:15:23,437 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 238\n",
            "[2024-01-28 18:15:24,490 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 239\n",
            "[2024-01-28 18:15:25,488 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 240\n",
            "[2024-01-28 18:15:26,478 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 241\n",
            "[2024-01-28 18:15:30,795 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 242\n",
            "[2024-01-28 18:15:31,794 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 243\n",
            "[2024-01-28 18:15:32,978 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 244\n",
            "[2024-01-28 18:15:34,872 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 245\n",
            "[2024-01-28 18:15:36,746 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 246\n",
            "[2024-01-28 18:16:22,090 INFO] Step 2000/ 3000; acc: 96.5; ppl:   4.3; xent: 1.5; lr: 0.00198; sents:   57183; bsz: 3024/3157/143; 14786/15437 tok/s;   1956 sec;\n",
            "[2024-01-28 18:16:22,170 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2)\n",
            "\n",
            "[2024-01-28 18:16:23,097 INFO] valid stats calculation\n",
            "                           took: 1.0055277347564697 s.\n",
            "[2024-01-28 18:16:23,099 INFO] Train perplexity: 15.8737\n",
            "[2024-01-28 18:16:23,099 INFO] Train accuracy: 70.0641\n",
            "[2024-01-28 18:16:23,099 INFO] Sentences processed: 1.19533e+06\n",
            "[2024-01-28 18:16:23,099 INFO] Average bsz: 3012/3161/149\n",
            "[2024-01-28 18:16:23,099 INFO] Validation perplexity: 24.0002\n",
            "[2024-01-28 18:16:23,099 INFO] Validation accuracy: 67.2468\n",
            "[2024-01-28 18:16:23,099 INFO] Model is improving ppl: 27.3657 --> 24.0002.\n",
            "[2024-01-28 18:16:23,099 INFO] Model is improving acc: 60.2551 --> 67.2468.\n",
            "[2024-01-28 18:16:23,104 INFO] Saving checkpoint models/model.bdqvie_step_2000.pt\n",
            "[2024-01-28 18:16:55,620 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=134)\n",
            "\n",
            "[2024-01-28 18:16:55,621 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 247\n",
            "[2024-01-28 18:16:56,723 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 248\n",
            "[2024-01-28 18:16:57,943 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 249\n",
            "[2024-01-28 18:17:04,070 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 250\n",
            "[2024-01-28 18:17:06,685 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 251\n",
            "[2024-01-28 18:17:08,436 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 252\n",
            "[2024-01-28 18:17:09,431 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 253\n",
            "[2024-01-28 18:17:14,341 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 254\n",
            "[2024-01-28 18:18:05,324 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=137)\n",
            "\n",
            "[2024-01-28 18:18:05,325 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 255\n",
            "[2024-01-28 18:18:06,359 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 256\n",
            "[2024-01-28 18:18:10,740 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 257\n",
            "[2024-01-28 18:18:11,709 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 258\n",
            "[2024-01-28 18:18:12,677 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 259\n",
            "[2024-01-28 18:18:13,651 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 260\n",
            "[2024-01-28 18:18:18,404 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 261\n",
            "[2024-01-28 18:18:19,415 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 262\n",
            "[2024-01-28 18:18:21,095 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 263\n",
            "[2024-01-28 18:18:46,374 INFO] Step 2100/ 3000; acc: 96.8; ppl:   4.3; xent: 1.5; lr: 0.00193; sents:   61315; bsz: 3031/3185/153; 8404/8830 tok/s;   2101 sec;\n",
            "[2024-01-28 18:19:13,948 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=134)\n",
            "\n",
            "[2024-01-28 18:19:13,949 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 264\n",
            "[2024-01-28 18:19:14,964 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 265\n",
            "[2024-01-28 18:19:15,965 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 266\n",
            "[2024-01-28 18:19:20,309 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 267\n",
            "[2024-01-28 18:19:21,262 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 268\n",
            "[2024-01-28 18:19:22,234 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 269\n",
            "[2024-01-28 18:19:23,206 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 270\n",
            "[2024-01-28 18:19:24,314 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 271\n",
            "[2024-01-28 18:20:08,623 INFO] Step 2200/ 3000; acc: 97.2; ppl:   4.2; xent: 1.4; lr: 0.00188; sents:   59727; bsz: 2996/3140/149; 14571/15272 tok/s;   2183 sec;\n",
            "[2024-01-28 18:20:20,624 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:20:20,625 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 272\n",
            "[2024-01-28 18:20:21,637 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 273\n",
            "[2024-01-28 18:20:22,635 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 274\n",
            "[2024-01-28 18:20:26,862 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 275\n",
            "[2024-01-28 18:20:27,843 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 276\n",
            "[2024-01-28 18:20:28,825 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 277\n",
            "[2024-01-28 18:20:30,403 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 278\n",
            "[2024-01-28 18:20:32,256 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 279\n",
            "[2024-01-28 18:20:37,817 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 280\n",
            "[2024-01-28 18:21:26,811 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:21:26,811 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 281\n",
            "[2024-01-28 18:21:27,816 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 282\n",
            "[2024-01-28 18:21:32,504 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 283\n",
            "[2024-01-28 18:21:34,368 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 284\n",
            "[2024-01-28 18:21:36,065 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 285\n",
            "[2024-01-28 18:21:37,100 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 286\n",
            "[2024-01-28 18:21:41,897 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 287\n",
            "[2024-01-28 18:21:42,887 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 288\n",
            "[2024-01-28 18:22:05,062 INFO] Step 2300/ 3000; acc: 97.4; ppl:   4.2; xent: 1.4; lr: 0.00184; sents:   59329; bsz: 3006/3169/148; 10328/10886 tok/s;   2299 sec;\n",
            "[2024-01-28 18:22:36,514 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:22:36,515 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 289\n",
            "[2024-01-28 18:22:38,274 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 290\n",
            "[2024-01-28 18:22:39,501 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 291\n",
            "[2024-01-28 18:22:40,497 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 292\n",
            "[2024-01-28 18:22:41,497 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 293\n",
            "[2024-01-28 18:22:45,888 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 294\n",
            "[2024-01-28 18:22:46,884 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 295\n",
            "[2024-01-28 18:22:47,875 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 296\n",
            "[2024-01-28 18:22:48,958 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 297\n",
            "[2024-01-28 18:23:27,084 INFO] Step 2400/ 3000; acc: 97.6; ppl:   4.1; xent: 1.4; lr: 0.00180; sents:   58642; bsz: 3006/3149/147; 14659/15359 tok/s;   2381 sec;\n",
            "[2024-01-28 18:23:44,149 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=134)\n",
            "\n",
            "[2024-01-28 18:23:44,149 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 298\n",
            "[2024-01-28 18:23:45,155 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 299\n",
            "[2024-01-28 18:23:46,142 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 300\n",
            "[2024-01-28 18:23:47,152 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 301\n",
            "[2024-01-28 18:23:51,580 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 302\n",
            "[2024-01-28 18:23:52,691 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 303\n",
            "[2024-01-28 18:23:54,392 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 304\n",
            "[2024-01-28 18:23:55,680 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 305\n",
            "[2024-01-28 18:24:47,366 INFO] Step 2500/ 3000; acc: 97.8; ppl:   4.1; xent: 1.4; lr: 0.00177; sents:   61011; bsz: 3022/3172/153; 15059/15803 tok/s;   2462 sec;\n",
            "[2024-01-28 18:24:48,664 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=137)\n",
            "\n",
            "[2024-01-28 18:24:48,665 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 306\n",
            "[2024-01-28 18:24:49,685 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 307\n",
            "[2024-01-28 18:24:50,712 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 308\n",
            "[2024-01-28 18:24:54,877 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 309\n",
            "[2024-01-28 18:24:56,238 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 310\n",
            "[2024-01-28 18:24:58,004 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 311\n",
            "[2024-01-28 18:24:59,808 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 312\n",
            "[2024-01-28 18:25:05,136 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 313\n",
            "[2024-01-28 18:25:06,114 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 314\n",
            "[2024-01-28 18:25:58,508 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=133)\n",
            "\n",
            "[2024-01-28 18:25:58,509 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 315\n",
            "[2024-01-28 18:26:00,085 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 316\n",
            "[2024-01-28 18:26:01,773 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 317\n",
            "[2024-01-28 18:26:02,756 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 318\n",
            "[2024-01-28 18:26:07,429 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 319\n",
            "[2024-01-28 18:26:08,431 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 320\n",
            "[2024-01-28 18:26:09,413 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 321\n",
            "[2024-01-28 18:26:10,414 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 322\n",
            "[2024-01-28 18:26:41,919 INFO] Step 2600/ 3000; acc: 98.0; ppl:   4.1; xent: 1.4; lr: 0.00173; sents:   59314; bsz: 2992/3138/148; 10448/10956 tok/s;   2576 sec;\n",
            "[2024-01-28 18:27:03,293 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=137)\n",
            "\n",
            "[2024-01-28 18:27:03,294 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 323\n",
            "[2024-01-28 18:27:04,847 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 324\n",
            "[2024-01-28 18:27:05,870 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 325\n",
            "[2024-01-28 18:27:10,097 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 326\n",
            "[2024-01-28 18:27:11,106 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 327\n",
            "[2024-01-28 18:27:12,100 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 328\n",
            "[2024-01-28 18:27:13,123 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 329\n",
            "[2024-01-28 18:27:18,456 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 330\n",
            "[2024-01-28 18:27:19,451 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 331\n",
            "[2024-01-28 18:28:04,613 INFO] Step 2700/ 3000; acc: 98.0; ppl:   4.0; xent: 1.4; lr: 0.00170; sents:   59010; bsz: 3032/3189/148; 14666/15428 tok/s;   2659 sec;\n",
            "[2024-01-28 18:28:10,773 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=135)\n",
            "\n",
            "[2024-01-28 18:28:10,773 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 332\n",
            "[2024-01-28 18:28:14,927 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 333\n",
            "[2024-01-28 18:28:15,966 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 334\n",
            "[2024-01-28 18:28:16,997 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 335\n",
            "[2024-01-28 18:28:18,632 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 336\n",
            "[2024-01-28 18:28:23,884 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 337\n",
            "[2024-01-28 18:28:24,903 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 338\n",
            "[2024-01-28 18:28:25,924 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 339\n",
            "[2024-01-28 18:29:19,752 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=135)\n",
            "\n",
            "[2024-01-28 18:29:19,752 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 340\n",
            "[2024-01-28 18:29:20,789 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 341\n",
            "[2024-01-28 18:29:22,072 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 342\n",
            "[2024-01-28 18:29:27,404 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 343\n",
            "[2024-01-28 18:29:29,229 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 344\n",
            "[2024-01-28 18:29:30,397 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 345\n",
            "[2024-01-28 18:29:31,432 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 346\n",
            "[2024-01-28 18:29:32,493 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 347\n",
            "[2024-01-28 18:30:02,922 INFO] Step 2800/ 3000; acc: 97.6; ppl:   4.1; xent: 1.4; lr: 0.00167; sents:   61767; bsz: 2978/3144/154; 10070/10632 tok/s;   2777 sec;\n",
            "[2024-01-28 18:30:27,532 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:30:27,533 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 348\n",
            "[2024-01-28 18:30:29,440 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 349\n",
            "[2024-01-28 18:30:30,751 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 350\n",
            "[2024-01-28 18:30:34,967 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 351\n",
            "[2024-01-28 18:30:36,009 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 352\n",
            "[2024-01-28 18:30:37,045 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 353\n",
            "[2024-01-28 18:30:38,098 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 354\n",
            "[2024-01-28 18:30:43,449 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 355\n",
            "[2024-01-28 18:30:44,479 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 356\n",
            "[2024-01-28 18:31:26,170 INFO] Step 2900/ 3000; acc: 98.1; ppl:   4.0; xent: 1.4; lr: 0.00164; sents:   58886; bsz: 3052/3183/147; 14664/15292 tok/s;   2860 sec;\n",
            "[2024-01-28 18:31:39,295 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:31:39,296 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 357\n",
            "[2024-01-28 18:31:40,361 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 358\n",
            "[2024-01-28 18:31:41,421 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 359\n",
            "[2024-01-28 18:31:42,466 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 360\n",
            "[2024-01-28 18:31:47,497 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 361\n",
            "[2024-01-28 18:31:48,533 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 362\n",
            "[2024-01-28 18:31:49,549 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 363\n",
            "[2024-01-28 18:31:50,586 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 364\n",
            "[2024-01-28 18:32:46,459 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=136)\n",
            "\n",
            "[2024-01-28 18:32:46,460 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 365\n",
            "[2024-01-28 18:32:47,564 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 366\n",
            "[2024-01-28 18:32:49,401 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 367\n",
            "[2024-01-28 18:32:50,949 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 368\n",
            "[2024-01-28 18:32:55,948 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 369\n",
            "[2024-01-28 18:32:57,069 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 370\n",
            "[2024-01-28 18:32:58,143 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 371\n",
            "[2024-01-28 18:32:59,200 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 372\n",
            "[2024-01-28 18:33:00,264 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 373\n",
            "[2024-01-28 18:33:26,180 INFO] Step 3000/ 3000; acc: 98.3; ppl:   4.0; xent: 1.4; lr: 0.00161; sents:   59955; bsz: 2981/3134/150; 9937/10446 tok/s;   2980 sec;\n",
            "[2024-01-28 18:33:26,339 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=2)\n",
            "\n",
            "[2024-01-28 18:33:27,742 INFO] valid stats calculation\n",
            "                           took: 1.55564284324646 s.\n",
            "[2024-01-28 18:33:27,744 INFO] Train perplexity: 10.122\n",
            "[2024-01-28 18:33:27,744 INFO] Train accuracy: 79.2709\n",
            "[2024-01-28 18:33:27,744 INFO] Sentences processed: 1.79429e+06\n",
            "[2024-01-28 18:33:27,744 INFO] Average bsz: 3011/3160/150\n",
            "[2024-01-28 18:33:27,744 INFO] Validation perplexity: 23.2373\n",
            "[2024-01-28 18:33:27,744 INFO] Validation accuracy: 68.2109\n",
            "[2024-01-28 18:33:27,744 INFO] Model is improving ppl: 24.0002 --> 23.2373.\n",
            "[2024-01-28 18:33:27,744 INFO] Model is improving acc: 67.2468 --> 68.2109.\n",
            "[2024-01-28 18:33:27,756 INFO] Saving checkpoint models/model.bdqvie_step_3000.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "L9X1d4orL0ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !onmt_translate -model models/model.bdqvie_step_3000.pt -src data/paralle.vie-bdq.bdq-filtered.bdq.subword.test -output data/paralle.vie.translated -gpu 0 -min_length 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRWrGsOVLj5L",
        "outputId": "6e1c00e8-6919-47d2-9f66-6cb8a11219da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-28 17:06:28.304060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-28 17:06:28.304121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-28 17:06:28.305523: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-28 17:06:28.313047: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-28 17:06:29.423848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-28 17:06:31.458443: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 17:06:31.458998: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-01-28 17:06:31.459211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2024-01-28 17:06:32,864 INFO] Loading checkpoint from models/model.bdqvie_step_3000.pt\n",
            "[2024-01-28 17:06:40,514 INFO] Loading data into the model\n",
            "[2024-01-28 17:07:15,126 INFO] PRED SCORE: -0.1126, PRED PPL: 1.12 NB SENTENCES: 2000\n",
            "Time w/o python interpreter load/terminate:  42.65310287475586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !tail -n 5 data/paralle.vie-bdq.bdq-filtered.bdq.subword.test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oT-1HTRLtgS",
        "outputId": "e77c997c-d63d-4ad7-cd9b-8e0fbe0168c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁' Nĕ ▁kơ ▁achăng ▁bôl ▁buăl ▁ih ▁dah ▁buăl ▁juăt ▁' bă ▁ih ,\n",
            "▁puôn\n",
            "▁chơpuih ▁( hnam )\n",
            "▁' Boi ▁quy ▁hoach ▁kŭm ▁trương ▁đơ̆ng ▁khu ▁vưk ▁lơ̆m ▁apung ▁teh ▁ngoai ▁thanh ▁uĕi ▁lơ̆m ▁kơbră ▁phương ▁Nhơn ▁Phŭ ▁jê̆ ▁Trương ▁Cao ▁đăng ▁' Binh ▁Đinh ▁weng ▁Trương ▁Đai ▁hŏk ▁Kuang ▁Trung\n",
            "▁Baasa ▁lôch ▁năm ▁oei ▁hơdai ▁hăm ▁lu ▁' bok ▁kơdră ▁sư , ▁păng ▁đe ▁' bŭ ▁sư ▁tơ ▁Pơlei ▁Tirsa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !tail -n 5 data/paralle.vie.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQzvWSBhMq_P",
        "outputId": "63c830d3-dfad-4ebf-aa3a-38b9b2941b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁Đừng ▁từ ▁bỏ ▁bạn ▁con ▁hay ▁bạn ▁của ▁cha ▁con ;\n",
            "▁bốn\n",
            "▁quét ▁( nhà )\n",
            "▁Theo ▁quy ▁hoạch ▁cụm ▁trường ▁của ▁khu ▁vực ▁tại ▁khu ▁đất ▁ngoại ▁thành ▁thuộc ▁phường ▁Nhơn ▁Phú ▁gần ▁Trường ▁Cao ▁đẳng ▁Bình ▁Định ▁và ▁Trường ▁Đại ▁học ▁Quang ▁Trung .\n",
            "▁Ba - ê - sa ▁an ▁giấc ▁với ▁các ▁tổ ▁phụ ▁mình ▁và ▁được ▁chôn ▁tại ▁Tiệt - sa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Desubword the translation file\n",
        "# !python /content/drive/MyDrive/bdq-mt/data-processing/subwording/3-desubword.py subwording/target.model data/paralle.vie.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzCdR_IbM0En",
        "outputId": "9976dee3-ba7a-467f-ff77-c09fc010e285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: data/paralle.vie.translated.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Desubword the target file (reference) of the test dataset\n",
        "# !python3 /content/drive/MyDrive/bdq-mt/data-processing/subwording/3-desubword.py subwording/target.model data/paralle.vie-bdq.vie-filtered.vie.subword.test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg9dipWUNc6k",
        "outputId": "28bee71c-cf41-4f9e-d0a6-3e0a2f30fbf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: data/paralle.vie-bdq.vie-filtered.vie.subword.test.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ctranslate2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKqrCSgn5XPv",
        "outputId": "b3779774-59c3-4107-d01c-1f4f649bee89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ctranslate2 in /usr/local/lib/python3.10/dist-packages (3.24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (1.23.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ct2-opennmt-py-converter --model_path models/model.bdqvie_step_3000.pt --output_dir models/bavi_ctranslate2 --quantization int8"
      ],
      "metadata": {
        "id": "zLxDeabq5hX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/bdq-mt/evaluation/translate.py data/all.vie-bdq.bdq-filtered.bdq.test subwording/source.model subwording/target.model models/bavi_ctranslate2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3SX_mx96BBK",
        "outputId": "46e11025-5ae3-447f-f367-dd187532f67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 data/all.vie-bdq.bdq-filtered.bdq.test.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdzMg3WW6nSt",
        "outputId": "45ed6451-10f8-46dc-d412-02765807ca21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cây điều chịu trách nhiệm được các phương châm đa dạng và khắc phục hậu quả tang đất với lượng mưa năm đủ và có một mùa khô ráo.\n",
            "Thấy Giô-sép cha mình suy nghiệm, anh con số người đó không được ơn trước mặt Giô-sép, và không còn nói ra nữa\n",
            "Sết sống tất cả được chín trăm mười hai năm, rồi qua đời\n",
            "Có ai nói với Đức Chúa Trời:\n",
            "học tập những chính sách có liên quan đến hoạt động của Ban Quản lý Di tích.\n",
            "màu tím\n",
            "Lời của CHÚA phán như vầy: “ Có một lần, mỗi năm một lần như những công bố những công việc của Đức Chúa Trời đã làm cho ngươi\n",
            "Vua Đa-vít nói với toàn thể hội chúng: “Giờ đây, con trai con gái của CHÚA, Đức Chúa Trời có thể chọn, gọi ta, ta không thể nào ghi nhớ việc này\n",
            "Thời gian thực hiện: từ tháng 9 năm 2018 đến hết tháng 12 năm 2020 (20), học kỳ học 90 hàng năm học theo).\n",
            "sốt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 data/all.vie-bdq.vie-filtered.vie.test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8DEULDm6n1F",
        "outputId": "6c2c373f-53a0-42bb-de4a-9cc29f192ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cây điều chịu được những điều kiện khí hậu đa dạng và khắc nghiệt. Khí hậu nhiệt đới với lượng mưa hàng năm đầy đủ và có một mùa khô rõ rệt là những điều kiện tối thích để cây điều phát triển tốt. Độ cao nơi trồng điều so với mặt biển càng lớn thì cây sinh trưởng càng chậm, năng suất càng giảm.\n",
            "Các anh Giô-sép ganh tỵ vì thấy cha thiên vị, nên họ không còn dịu ngọt với Giô-sép nữa\n",
            "Sết sống tất cả chín trăm mười hai năm, rồi qua đời\n",
            "Có ai từng thưa với Đức Chúa Trời:\n",
            "Hoặc bổ sung các chính sách liên quan đến hoạt động của Ban Quản lý Di tích.\n",
            "bầm tím\n",
            "Vì Chúa đã phán cùng tôi như vầy: “Trong vòng một năm, như các năm của một người làm thuê, tất cả vinh quang của Kê-đa sẽ chấm dứt\n",
            "Vua Đa-vít nói với toàn hội chúng: “Sa-lô-môn, con trai ta, người mà Đức Chúa Trời đã chọn, hãy còn trẻ, thiếu kinh nghiệm, còn công việc thì lớn lao vì đền này không phải xây cho người phàm nhưng cho CHÚA, là Đức Chúa Trời\n",
            "Thời gian thực hiện: Từ tháng 9/2018 đến hết tháng 12/2020 (05 học kỳ, tương đương 90 tuần theo năm học).\n",
            "sốt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "IAltMCfWL1zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3z8gmYDN4Xu",
        "outputId": "a1914f58-2bc9-4ef1-90bc-a88be70285cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/bdq-mt/evaluation/eval-metrics.py   data/all.vie-bdq.vie-filtered.vie.test data/all.vie-bdq.bdq-filtered.bdq.test.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyBcxG4SObrk",
        "outputId": "80f85b81-79d2-4236-84ed-ae172fae60dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU:  49.61\n",
            "CHRF: 59.51\n",
            "TER: 48.49\n"
          ]
        }
      ]
    }
  ]
}